{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UPz2dPvRgHb3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jKzH0MmeZXA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/PCOS_Dataset_BNN_Causal.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_N-onefeqDW",
        "outputId": "73edad43-c9f4-4f76-c8dc-899fffdbd45d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(728, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "UPz2dPvRgHb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'AMH(ng/mL)': [2.07, 1.53, 6.63, 1.22, 2.26, 6.74, 3.05, 1.54, 1.0, 1.61, 4.47, 1.67, 7.94, 2.38, 0.88, 0.69, 3.78, 1.92, 1.0, 2.07, 2.85, 2.13, 4.13, 2.5, 1.89, 0.26, 3.84, 2.5, 3.56, 1.56, 1.69, 1.89, 2.34, 1.58, 2.36, 3.64, 2.78, 0.88, 2.36, 0.33, 2.35, 3.88, 3.55, 4.33, 3.55, 2.36, 3.66, 4.33, 1.0, 4.5, 3.2, 2.1, 4.5, 6.55, 1.2, 2.33, 3.22, 2.333, 2.31, 2.36, 4.2, 3.21, 2.14, 2.3, 4.6, 2.3, 5.8, 5.2, 2.14, 4.63, 1.01, 2.58, 5.8, 0.35, 5.23, 3.68, 2.14, 2.55, 4.91, 1.03, 6.56, 3.91, 5.42, 1.65, 2.06, 1.81, 3.81, 2.26, 3.65, 8.98, 1.7, 3.18, 2.75, 0.86, 2.29, 2.19, 8.46, 4.59, 1.04, 4.27, 3.86, 1.42, 10.07, 0.98, 4.07, 3.2, 3.9, 10.0, 16.9, 17.0, 21.9, 1.6, 3.3, 21.0, 12.7, 1.8, 3.6, 15.0, 5.0, 3.3, 3.3, 3.9, 17.9, 19.8, 9.2, 2.4, 4.5, 5.14, 2.4, 0.3, 11.48, 19.3, 8.8, 19.0, 4.3, 1.4, 12.6, 4.8, 4.6, 17.1, 2.1, 11.6, 18.4, 1.8, 9.9, 3.7, 2.9, 2.0, 4.0, 1.6, 15.9, 7.51, 10.04, 6.86, 7.02, 8.75, 5.27, 1.4, 9.0, 3.56, 3.41, 0.45, 2.53, 0.29, 2.6, 2.83, 1.89, 2.01, 2.83, 5.67, 1.68, 3.65, 3.63, 3.49, 2.01, 8.0, 9.0, 11.48, 10.25, 2.36, 32.0, 3.38, 1.35, 2.38, 5.78, 4.66, 1.99, 1.28, 3.99, 5.69, 7.81, 6.41, 5.76, 1.68, 8.75, 6.65, 4.15, 1.86, 2.04, 7.25, 1.04, 1.91, 2.3, 5.61, 3.02, 5.25, 2.38, 7.0, 3.17, 5.57, 4.57, 0.37, 16.9, 26.4, 5.96, 9.1, 6.6, 22.0, 1.9, 4.3, 0.37, 17.6, 1.1, 7.8, 2.9, 7.7, 9.7, 0.2, 2.5, 12.0, 1.4, 16.7, 13.6, 16.8, 3.5, 1.3, 3.14, 1.25, 7.7, 7.3, 7.2, 3.29, 2.69, 2.1, 4.1, 6.2, 14.6, 4.71, 1.25, 1.0, 11.1, 1.9, 6.2, 1.9, 1.5, 2.9, 2.25, 6.8, 0.8, 7.21, 4.2, 6.2, 0.9, 16.8, 16.9, 8.5, 3.9, 66.0, 26.8, 1.15, 4.1, 3.2, 0.16, 8.1, 0.56, 5.3, 1.8, 7.3, 6.5, 21.0, 0.9, 15.3, 10.6, 4.2, 4.7, 4.8, 1.7, 5.4, 1.2, 5.4, 17.5, 6.0, 2.0, 21.8, 18.5, 12.4, 10.8, 4.5, 4.2, 1.2, 10.8, 10.0, 18.7, 18.0, 0.28, 3.7, 1.03, 3.02, 1.0, 1.5, 3.0, 1.0, 1.06, 3.05, 5.4, 3.02, 2.23, 2.06, 3.33, 1.0, 2.65, 11.0, 3.6, 5.7, 1.03, 6.33, 2.5, 2.2, 15.7, 3.5, 1.1, 1.3, 3.0, 3.0, 2.17, 3.3, 14.7, 2.8, 1.06, 9.1, 5.9, 8.9, 3.6, 2.31, 3.6, 2.8, 20.4, 1.5, 4.6, 5.0, 3.9, 9.8, 3.65, 3.5, 10.7, 4.8, 4.5, 2.6, 3.9, 3.09, 10.9, 5.2, 1.6, 1.0, 6.4, 2.8, 6.4, 2.19, 15.0, 2.5, 4.2, 5.1, 6.0, 5.8, 0.2, 9.0, 1.2, 9.1, 2.9, 3.1, 5.6, 7.9, 18.9, 11.4, 3.8, 4.5, 2.0, 4.5, 3.1, 2.9, 9.1, 1.2, 9.0, 0.2, 5.8, 6.0, 5.1, 2.5, 1.6, 1.9, 1.14, 5.7, 28.6, 5.5, 3.8, 4.2, 0.5, 0.9, 4.8, 1.3, 6.4, 8.1, 10.8, 5.2, 7.2, 15.0, 3.4, 2.28, 2.6, 4.8, 11.9, 6.9, 0.1, 12.8, 2.7, 6.0, 0.84, 2.9, 4.6, 20.0, 8.9, 1.2, 2.8, 10.3, 9.9, 2.5, 3.6, 8.0, 1.01, 10.2, 11.0, 0.6, 0.5, 0.37, 16.9, 26.4, 5.96, 6.2, 9.1, 0.8, 0.91, 0.98, 0.89, 0.87, 9.7, 7.7, 1.1, 17.6, 6.6, 5.0, 7.0, 9.0, 0.7, 10.0, 0.85, 6.0, 6.0, 0.78, 16.0, 0.74, 0.91, 0.99, 0.9, 4.13, 4.02, 6.09, 0.71, 3.62, 0.89, 1.97, 1.4, 3.03, 3.86, 5.75, 6.26, 0.72, 10.53, 10.32, 2.39, 2.7, 1.1, 4.9, 10.6, 4.3, 5.1, 16.8, 7.9, 3.1, 5.1, 11.2, 1.7, 5.2, 2.2, 1.3, 12.0, 3.3, 1.7, 0.9, 4.9, 16.6, 17.6, 4.6, 5.5, 2.2, 18.9, 10.0, 16.0, 5.4, 3.7, 5.5, 7.2, 2.5, 18.5, 7.7, 0.19, 0.6, 2.5, 3.7, 0.8, 2.3, 1.0, 0.7, 6.3, 19.6, 18.2, 7.6, 1.7, 5.6, 3.7, 5.2, 20.0, 17.28069933478436, 13.787854732572589, 5.936959182149734, 6.636284856933916, 5.595461865954144, 5.512376864960425, 14.120166122937189, 2.104295746188055, 6.960127567719773, 18.858466525445508, 8.793376893185009, 3.211422404692585, 14.044659995676003, 21.97665605178377, 6.863811752685999, 3.784813774869293, 3.086423123315166, 2.3754565441252677, 4.943954039046507, 13.510312722754866, 0.1033824504695528, 5.510063294423191, 2.962213487345557, 1.521518984045931, 2.6482922516572005, 34.44241716424378, 3.9743993017570647, 6.533921499815991, 8.94875891555245, 10.91617791908379, 16.965492757970445, 12.20064556530173, 4.339813382496917, 3.799117884321341, 9.957997273975504, 2.2996623188084127, 2.436261199504931, 15.996754132342646, 9.86705234129358, 7.992091697671297, 6.3715951491402265, 6.327390618342859, 12.862037333522109, 8.23135513030384, 3.8056412322401463, 4.395334897516303, 13.052303254484077, 12.56085983324911, 13.599705594720572, 3.235330183196504, 15.519663962673327, 9.892875788498204, 2.775196676124917, 14.44303214196192, 5.021604589208082, 8.04645063929552, 15.88508082680536, 2.731268050004142, 1.515967312321901, 5.253156256372819, 5.555431525716015, 5.314756544321456, 9.996921173647966, 0.8335137545994087, 1.4571972582204564, 8.881069834314603, 4.964356075392558, 5.218906486066236, 9.486200611437445, 16.027513389655272, 11.413243050497355, 8.233687254827558, 9.904587687761866, 2.721481116498061, 8.535202143062262, 2.40191595913519, 4.630928947871426, 6.141457985429864, 1.9105390016372945, 7.916747820390252, 0.6116413743012062, 5.878780328562028, 6.614500923261869, 4.43612936642807, 10.045948752445874, 0.8636851698811197, 10.950724967539468, 1.2104027830931026, 14.959928484620375, 8.704060618018298, 12.363148903760388, 1.6872961118698298, 20.05747028324876, 13.134632156728244, 5.005034555575681, 15.824557824821078, 1.258717786696983, 5.760156926532144, 6.570557181131415, 14.988545930550387, 17.1970103170339, 7.1401334424577785, 1.6330750447154418, 1.1775133750951048, 4.501858542156236, 16.372075988444422, 14.523352042172888, 3.6048688729275407, 15.710562786245312, 19.261086932208983, 6.558477263247355, 1.8207481676681336, 3.2001334724286883, 11.197601458365844, 8.584200487135673, 8.228014610822015, 6.979656328604483, 15.2304321073134, 7.813684441811862, 2.260350982140244, 0.9058987084756056, 2.0940621415664893, 3.358334526978397, 4.394404733033696, 18.00229013720527, 1.9962007236983697, 5.094231361659641, 6.036417600514465, 1.6398238102378269, 2.514840489910503, 9.014357838051408, 9.008058788928563, 5.769433795708108, 1.5312443278160977, 1.805994438122925, 4.839064434828902, 7.795142666503679, 10.019409949183936, 7.543182491079783, 1.142960777053593, 2.458059049427997, 16.22987534583904, 11.254634427754002, 17.940994751148136, 8.397229951950974, 4.625891221509246, 7.936377218052422, 6.2151299445004256, 2.675347672721053, 6.255254927291047, 10.99509116670284, 7.201482050324197, 3.735455387751296, 1.9021632836700733, 17.41969844875927, 8.993246324085572, 1.054338742923755, 6.2, 7.302477916653542, 4.035516905472039, 5.2913129961791725, 18.021825339952898, 2.7125933895589496, 1.674932775984224, 5.224541919109435, 2.0869878840900906, 4.631524793706745, 3.7906603278089945, 10.561478409358411, 0.20565828557744, 4.811082143970244, 1.7162574884289017, 2.864841128239658, 2.371555708682555, 6.561062298723396, 5.727881157481583, 18.03217188445944, 10.88407032236285, 3.0311116878894087, 2.88559221140482, 0.9143694665050536, 9.13953745505497, 2.2790987955413327, 9.631990347436872, 16.459364053272488, 2.2737492617638444, 7.582425103178169], 'Pulse rate(bpm) ': [78, 74, 72, 72, 72, 78, 72, 72, 72, 80, 80, 72, 72, 74, 74, 78, 80, 72, 72, 72, 70, 72, 74, 74, 72, 80, 75, 72, 78, 78, 78, 72, 72, 72, 76, 72, 74, 70, 78, 74, 78, 72, 78, 72, 78, 70, 72, 74, 78, 72, 72, 72, 72, 70, 70, 72, 72, 72, 72, 74, 78, 78, 70, 80, 72, 70, 78, 78, 80, 80, 72, 74, 70, 72, 72, 72, 80, 72, 75, 80, 72, 72, 78, 72, 74, 70, 74, 80, 74, 72, 78, 74, 78, 72, 70, 80, 78, 78, 72, 78, 72, 78, 78, 72, 72, 74, 72, 72, 72, 74, 72, 72, 72, 72, 72, 72, 80, 74, 78, 72, 76, 70, 72, 74, 78, 72, 72, 72, 70, 72, 72, 72, 70, 70, 72, 72, 78, 72, 70, 72, 72, 74, 72, 70, 80, 74, 72, 70, 72, 80, 78, 76, 72, 74, 72, 76, 72, 73, 74, 73, 72, 75, 73, 72, 74, 73, 74, 73, 74, 72, 73, 74, 75, 72, 72, 74, 73, 74, 74, 72, 74, 73, 73, 72, 73, 72, 74, 75, 72, 74, 73, 74, 72, 72, 74, 72, 73, 72, 72, 74, 73, 72, 74, 73, 72, 73, 75, 73, 72, 74, 72, 78, 82, 72, 72, 74, 72, 72, 72, 78, 72, 80, 78, 18, 70, 70, 72, 72, 74, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 74, 72, 72, 72, 72, 72, 72, 72, 72, 72, 74, 72, 72, 74, 72, 70, 72, 74, 74, 72, 72, 72, 72, 70, 72, 72, 72, 78, 72, 74, 72, 72, 72, 72, 72, 70, 74, 72, 72, 72, 72, 78, 78, 72, 70, 74, 72, 70, 72, 72, 13, 72, 74, 72, 72, 72, 72, 72, 70, 74, 72, 72, 72, 72, 72, 72, 74, 72, 78, 72, 72, 74, 72, 72, 72, 72, 72, 78, 74, 80, 72, 74, 70, 72, 72, 70, 72, 80, 74, 78, 78, 78, 78, 78, 78, 75, 78, 78, 78, 78, 74, 72, 72, 72, 72, 78, 72, 74, 80, 72, 72, 74, 78, 70, 72, 78, 74, 72, 72, 72, 72, 72, 74, 74, 72, 72, 72, 70, 74, 72, 72, 74, 72, 74, 72, 82, 72, 72, 72, 72, 72, 74, 74, 72, 74, 72, 72, 74, 70, 72, 72, 74, 72, 80, 74, 72, 74, 78, 72, 74, 72, 74, 72, 74, 72, 78, 78, 74, 74, 80, 74, 72, 74, 72, 74, 78, 74, 74, 72, 74, 74, 72, 74, 72, 72, 72, 72, 72, 72, 72, 70, 74, 72, 72, 70, 74, 72, 78, 82, 72, 72, 72, 74, 72, 80, 72, 74, 72, 72, 70, 78, 80, 72, 74, 72, 72, 78, 78, 72, 70, 70, 72, 72, 74, 80, 80, 72, 78, 70, 72, 78, 74, 72, 72, 70, 70, 72, 72, 72, 80, 74, 74, 72, 72, 80, 72, 72, 72, 80, 72, 70, 72, 72, 74, 72, 72, 80, 70, 72, 74, 78, 74, 78, 74, 70, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 74, 72, 72, 72, 72, 74, 74, 72, 70, 72, 72, 72, 70, 70, 70, 72, 72, 74, 74, 80, 74, 72, 72, 72, 72, 78, 77, 76, 72, 72, 72, 73, 72, 71, 78, 72, 78, 73, 73, 72, 73, 75, 76, 77, 73, 75, 75, 72, 72, 72, 70, 72, 72, 75, 74, 73, 76, 73, 72, 73, 72, 72, 74, 74, 75, 74, 73, 75, 71, 72, 77, 73, 75, 73, 73, 72, 78, 76, 73, 74, 74, 75, 72, 79, 72, 74, 72, 72, 75, 79, 74, 74, 72, 72, 73, 73, 72, 75, 71, 78, 72, 77, 72, 72, 77, 72, 76, 74, 72, 72, 77, 72, 79, 71, 72, 79, 72, 72, 72, 74, 72, 73, 72, 72, 74, 72, 78, 74, 78, 70, 72, 72, 74, 71, 74, 71, 73, 72, 72, 72, 76, 72, 74, 72, 70, 75, 77, 74, 72, 76, 72, 76, 76, 72, 72, 71, 75, 72, 74, 70, 73, 72, 74, 72, 73, 72, 72, 72, 72, 76, 73, 72, 77, 79, 76, 76, 72, 72, 74, 78, 78, 72, 72, 79, 72, 75, 75, 74, 72, 72, 72, 72, 73, 72, 72, 72, 72, 73, 71, 72, 72, 72, 79, 74, 70, 72, 73], ' Age (yrs)': [28, 36, 33, 37, 25, 36, 34, 33, 32, 36, 20, 26, 25, 38, 34, 38, 29, 36, 31, 30, 25, 38, 34, 28, 34, 41, 30, 20, 25, 28, 32, 34, 31, 38, 28, 32, 37, 26, 36, 20, 32, 29, 28, 24, 29, 25, 28, 26, 34, 27, 23, 23, 31, 32, 32, 37, 38, 36, 26, 26, 29, 32, 24, 29, 27, 32, 41, 35, 35, 34, 33, 29, 36, 26, 35, 36, 32, 34, 37, 38, 36, 34, 39, 35, 34, 27, 31, 40, 22, 36, 44, 35, 28, 32, 27, 22, 28, 31, 32, 32, 30, 34, 38, 34, 29, 25, 28, 27, 24, 34, 21, 26, 39, 32, 29, 29, 35, 28, 33, 29, 30, 33, 22, 23, 26, 38, 40, 42, 41, 40, 24, 25, 22, 28, 35, 30, 26, 35, 27, 35, 36, 28, 30, 32, 37, 35, 36, 28, 23, 24, 28, 29, 31, 29, 26, 26, 27, 34, 25, 32, 36, 38, 23, 32, 35, 32, 29, 29, 30, 33, 28, 29, 31, 35, 37, 27, 28, 24, 37, 35, 30, 30, 42, 36, 26, 27, 32, 43, 28, 23, 34, 29, 30, 30, 29, 35, 35, 28, 32, 25, 30, 28, 28, 23, 30, 28, 24, 32, 27, 35, 32, 39, 27, 26, 29, 41, 36, 34, 26, 27, 39, 31, 27, 30, 36, 32, 35, 29, 31, 28, 40, 22, 35, 31, 27, 28, 33, 25, 32, 20, 24, 23, 37, 29, 39, 23, 26, 24, 33, 29, 45, 30, 47, 36, 28, 36, 33, 27, 43, 31, 38, 32, 38, 37, 34, 40, 25, 28, 25, 26, 30, 26, 43, 30, 30, 27, 36, 29, 45, 26, 31, 31, 38, 32, 32, 38, 26, 29, 35, 27, 27, 35, 30, 27, 28, 30, 31, 20, 34, 26, 40, 28, 26, 25, 35, 37, 41, 24, 33, 24, 39, 30, 28, 38, 34, 28, 30, 28, 47, 32, 33, 38, 28, 37, 40, 35, 45, 31, 30, 29, 33, 29, 27, 31, 30, 30, 21, 36, 31, 29, 26, 26, 32, 25, 36, 30, 28, 31, 32, 30, 22, 36, 27, 30, 33, 28, 32, 32, 34, 36, 34, 35, 42, 31, 35, 38, 23, 20, 22, 35, 28, 31, 29, 28, 32, 27, 35, 28, 23, 31, 37, 35, 29, 32, 37, 41, 40, 24, 31, 23, 28, 35, 27, 32, 28, 29, 31, 35, 36, 30, 27, 28, 28, 27, 26, 33, 33, 36, 45, 40, 34, 40, 23, 26, 30, 31, 26, 32, 27, 36, 25, 40, 38, 42, 29, 37, 33, 32, 28, 33, 25, 42, 29, 33, 23, 30, 29, 32, 33, 34, 26, 31, 40, 39, 27, 26, 29, 47, 41, 33, 34, 30, 31, 35, 35, 32, 31, 31, 36, 36, 27, 33, 33, 41, 34, 33, 35, 32, 40, 25, 34, 31, 26, 39, 48, 31, 32, 42, 28, 27, 26, 44, 32, 33, 31, 30, 30, 36, 36, 28, 35, 23, 25, 30, 30, 27, 34, 35, 23, 28, 40, 38, 38, 31, 33, 35, 35, 37, 36, 46, 24, 44, 23, 21, 32, 31, 34, 27, 24, 28, 27, 40, 29, 36, 27, 27, 32, 22, 41, 32, 38, 34, 39, 26, 24, 26, 35, 30, 36, 27, 23, 35, 38, 27, 34, 26, 28, 28, 30, 27, 32, 27, 29, 33, 33, 29, 28, 33, 27, 33, 28, 37, 34, 31, 27, 26, 30, 28, 24, 31, 34, 29, 27, 28, 30, 34, 32, 28, 30, 38, 31, 36, 29, 25, 31, 33, 27, 22, 28, 24, 29, 25, 30, 31, 28, 37, 33, 28, 30, 30, 28, 28, 25, 28, 34, 29, 28, 31, 24, 32, 30, 28, 28, 28, 32, 31, 32, 32, 24, 24, 34, 27, 25, 34, 25, 37, 31, 26, 32, 26, 31, 35, 36, 23, 26, 26, 29, 33, 32, 33, 33, 25, 31, 39, 33, 30, 29, 27, 41, 30, 26, 24, 32, 30, 30, 26, 35, 26, 26, 23, 30, 30, 30, 26, 31, 30, 27, 32, 34, 30, 30, 29, 30, 35, 33, 35, 25, 25, 39, 33, 26, 36, 26, 28, 25, 25, 27, 35, 31, 26, 29, 29, 35, 30, 33, 30, 32, 27, 47, 28, 35, 32, 27, 33, 33, 33, 30, 28, 26, 43, 27, 28, 30, 23, 30, 23, 29, 28, 25, 29, 30, 30, 27, 32, 36, 28, 39, 30], 'BMI': [19.3, 24.9, 25.3, 29.7, 20.1, 27.2, 26.3, 23.1, 16.0, 23.1, 26.7, 19.1, 32.0, 21.6, 21.8, 33.9, 19.6, 27.0, 20.7, 31.2, 26.3, 20.5, 26.7, 28.1, 25.2, 18.2, 29.7, 29.4, 24.8, 24.2, 20.8, 25.3, 24.1, 19.8, 20.0, 26.1, 29.2, 29.2, 21.2, 25.3, 16.4, 28.7, 13.4, 25.0, 23.6, 23.3, 27.5, 16.4, 21.2, 21.5, 23.0, 21.6, 20.3, 27.2, 25.1, 23.8, 21.9, 25.1, 30.0, 35.7, 24.0, 29.3, 20.8, 25.5, 24.9, 24.0, 21.9, 26.8, 23.5, 23.6, 24.0, 26.8, 27.4, 26.3, 25.5, 30.4, 18.6, 23.1, 21.3, 38.3, 25.3, 22.9, 20.1, 20.5, 24.7, 26.3, 26.3, 23.0, 24.6, 28.5, 29.8, 20.0, 31.4, 21.4, 26.4, 20.8, 28.5, 38.5, 23.0, 25.4, 24.9, 28.2, 29.0, 22.3, 23.7, 21.2, 23.4, 22.2, 23.9, 31.3, 26.2, 26.0, 24.6, 23.4, 28.2, 26.8, 26.2, 28.3, 31.6, 23.8, 24.9, 21.9, 32.9, 17.8, 30.9, 22.5, 23.6, 21.9, 24.0, 19.0, 29.7, 21.1, 25.3, 28.4, 28.7, 27.7, 25.6, 19.3, 23.0, 27.4, 22.7, 22.8, 27.6, 20.0, 29.0, 26.6, 31.6, 28.1, 22.9, 22.5, 24.0, 25.1, 24.7, 24.1, 17.2, 19.7, 21.3, 25.6, 26.3, 25.6, 24.5, 24.2, 26.0, 25.0, 26.6, 20.4, 26.1, 26.7, 29.0, 22.4, 21.9, 24.7, 22.5, 30.6, 26.0, 25.1, 31.2, 29.7, 31.2, 21.4, 31.1, 21.0, 21.6, 28.4, 22.2, 21.5, 27.5, 26.9, 32.0, 22.9, 23.1, 26.9, 24.0, 18.2, 21.6, 25.5, 23.0, 28.0, 20.7, 22.7, 18.8, 22.4, 30.1, 23.3, 21.0, 24.2, 32.0, 28.5, 22.7, 29.1, 25.7, 24.4, 23.1, 31.1, 27.3, 27.7, 25.1, 28.8, 19.1, 32.0, 26.4, 12.4, 26.0, 21.7, 26.8, 23.1, 24.4, 28.2, 28.2, 31.3, 30.7, 32.9, 21.0, 21.6, 19.5, 24.8, 25.3, 17.7, 24.5, 22.2, 19.5, 24.3, 25.7, 27.3, 38.5, 24.3, 20.3, 29.0, 27.8, 21.1, 36.3, 29.1, 26.4, 20.4, 21.4, 13.5, 15.6, 19.9, 14.3, 19.9, 14.5, 15.6, 21.3, 18.5, 14.6, 13.9, 26.1, 23.3, 23.2, 24.9, 19.6, 21.2, 17.3, 22.5, 25.2, 20.3, 28.8, 29.3, 21.1, 24.0, 26.0, 21.2, 26.1, 27.2, 19.9, 21.4, 28.3, 22.9, 27.5, 24.8, 30.9, 21.2, 27.2, 15.4, 26.8, 23.7, 20.8, 23.1, 29.0, 21.6, 28.4, 22.9, 27.3, 26.0, 23.1, 24.2, 16.6, 27.2, 22.5, 19.8, 22.0, 27.8, 22.4, 19.1, 22.0, 23.3, 28.6, 21.0, 22.2, 25.3, 24.4, 22.2, 27.1, 23.3, 25.6, 22.8, 23.4, 21.2, 25.1, 20.4, 22.9, 24.6, 23.6, 19.2, 26.8, 17.7, 32.8, 34.3, 28.2, 22.9, 26.0, 26.0, 16.0, 32.8, 24.8, 21.6, 30.9, 22.4, 23.1, 28.8, 23.6, 24.7, 22.3, 20.4, 21.6, 24.4, 29.5, 18.8, 25.2, 25.7, 25.7, 28.3, 19.3, 20.8, 19.2, 30.1, 29.0, 23.5, 22.4, 26.0, 21.6, 26.2, 29.3, 15.8, 25.1, 24.0, 26.0, 26.4, 20.8, 24.3, 25.1, 28.1, 20.4, 24.2, 22.8, 28.2, 21.5, 26.0, 24.3, 20.8, 26.4, 26.0, 18.0, 25.1, 15.8, 29.3, 26.2, 26.0, 25.3, 24.6, 22.4, 25.9, 25.0, 25.0, 17.3, 20.0, 22.3, 24.6, 22.3, 23.1, 21.9, 23.6, 23.2, 23.1, 25.6, 23.5, 20.3, 27.4, 25.4, 24.5, 19.7, 27.6, 25.3, 24.4, 20.4, 26.9, 25.6, 25.2, 21.9, 26.0, 27.4, 26.0, 22.8, 21.5, 28.0, 22.1, 21.3, 28.8, 28.3, 28.2, 20.3, 22.1, 22.4, 24.4, 23.1, 32.0, 24.0, 24.5, 27.9, 24.9, 24.6, 16.9, 20.0, 24.0, 24.4, 23.1, 21.0, 15.1, 25.1, 23.2, 25.2, 21.9, 33.5, 17.6, 23.1, 22.2, 26.4, 24.4, 25.6, 23.2, 23.4, 21.6, 25.1, 21.1, 24.1, 22.6, 22.4, 38.9, 23.4, 23.9, 19.2, 30.8, 16.5, 35.2, 25.9, 18.2, 19.4, 26.8, 28.2, 30.8, 25.7, 24.4, 24.0, 21.1, 21.9, 26.6, 20.0, 27.6, 23.7, 24.5, 25.5, 25.8, 23.1, 22.6, 18.3, 22.5, 18.1, 26.5, 24.1, 23.4, 22.7, 27.8, 26.4, 21.9, 22.3, 25.7, 21.6, 25.2, 23.6, 21.1, 17.7, 32.5, 21.9, 26.7, 24.0, 19.1, 25.0, 23.6, 27.1, 19.6, 24.4, 26.0, 22.3, 20.5, 19.1, 30.7, 18.5, 25.3, 23.4, 22.2, 30.1, 28.87911652414444, 23.7452213473782, 17.537551020212184, 25.580005001218822, 19.103970867290123, 25.26748383929529, 24.51398829223439, 28.76346892779931, 20.74939327829074, 24.46549202428573, 24.750029512110693, 26.350495300453066, 27.30056418766668, 27.23595546951284, 21.64329705461371, 26.89710974948778, 33.47620048311465, 25.26955981816405, 27.36820509532323, 28.235230987945865, 25.29989592460094, 26.5967611200274, 20.66474061602617, 26.24698377971441, 22.417038154939664, 23.93027896276668, 20.69983315724265, 29.188588633658966, 25.774152297890208, 26.44242983616841, 27.52494312170772, 19.02766301311272, 24.569258721037485, 29.674043101156407, 29.981206013115145, 21.259067920476863, 22.639956926665143, 26.195768238841328, 28.562895622948737, 28.780794122916006, 24.133218985724717, 29.222829354247757, 25.588962986681768, 28.783474633549726, 30.359851642957185, 25.290305403410407, 23.996472742226164, 23.478850458370584, 22.201576025377747, 23.90338995830685, 30.54803360373267, 19.804266631663573, 22.732689010455264, 28.27578400617226, 24.872339490712925, 26.64458545623593, 23.99171157044742, 29.10176333633317, 20.20192493945868, 24.316855737470647, 26.34234508732791, 27.475403669777844, 24.39963054438097, 24.571671760962744, 28.85309588254643, 30.605349171573017, 22.25540187024793, 28.847600836911774, 25.64139816568767, 12.90973572078453, 23.139017392409254, 21.56737450965512, 29.916272433997783, 25.78424361873362, 23.824363316006057, 21.350397791872066, 25.92721486221314, 28.65309507175507, 24.808735319803525, 24.58572498910135, 24.24493689793431, 26.05349497001169, 25.1966728217458, 28.608756237754385, 28.97489978837809, 24.289341924124138, 19.45468893813536, 22.21817311372148, 25.86790502416104, 27.3797245364458, 24.36896229307896, 24.076669428880848, 30.21494056649753, 27.429180494906745, 22.038703525947398, 16.2627580996134, 22.75242896879312, 22.44293186977721, 25.96341644340008, 23.29733805153578, 25.16195582712833, 25.53414678670356, 30.713168081622342, 27.448237075787603, 27.284174989478373, 33.55396401147593, 22.965472757104127, 38.795246043344505, 14.45832545632494, 20.546995945400354, 22.604885027853253, 24.52517589645493, 29.256528149208, 23.546502313833937, 25.96512790910256, 36.15873798192184, 21.4276206916647, 29.331730676619536, 23.64553519271667, 30.648983999067717, 24.805064576219728, 31.159896430722515, 23.77159237401894, 26.178896182635373, 24.361529578632272, 26.52511761154201, 25.103503862253287, 24.70406330739358, 28.22716648698562, 28.08001807831976, 29.106130312875884, 25.340381943400512, 24.688675914162147, 27.75203585107012, 28.78038183887043, 25.55792231958732, 24.99239480273342, 29.576710375110785, 21.00697831378957, 24.787372432857488, 28.54934811104281, 29.489953880607764, 25.68796041984418, 26.045237357453097, 26.013684227176714, 29.424363413207683, 24.317264772283583, 25.48793239982311, 22.324975786269736, 22.80995555380345, 22.544432827623464, 27.13620320596633, 23.66298484867025, 23.74503904116276, 35.32443549224652, 19.28856483175949, 24.50210549381463, 24.982910933232503, 27.35833670672712, 25.083826146357904, 22.752550851578174, 26.198866141655078, 24.46574240494381, 22.38204994226977, 25.27034898563522, 28.66417531484298, 22.6818276379539, 24.302174038674675, 35.745159573278364, 24.02747977270213, 20.19310741984414, 27.178323348761467, 25.76589497390024, 30.32707558012945, 26.68430377382062, 27.79200808104377, 26.728196393128368, 24.989902543360696, 27.4830190341168, 22.202575106477838, 19.36114500606049, 30.703866826471216, 18.710770581305763, 28.097224574339897, 27.911416164090863, 19.1775890133134, 20.16019272067713], 'RR (breaths/min)': [22, 20, 18, 20, 18, 28, 18, 20, 18, 20, 20, 20, 18, 20, 22, 22, 20, 18, 18, 18, 18, 18, 20, 22, 20, 20, 18, 20, 22, 22, 22, 22, 18, 18, 20, 22, 18, 18, 22, 16, 22, 16, 18, 16, 22, 18, 18, 18, 24, 18, 16, 18, 20, 18, 18, 18, 20, 20, 18, 20, 22, 22, 20, 20, 18, 18, 20, 22, 20, 20, 18, 20, 18, 18, 20, 18, 20, 18, 20, 20, 18, 16, 20, 20, 20, 18, 18, 20, 20, 18, 22, 20, 22, 20, 20, 20, 24, 24, 20, 22, 18, 22, 20, 20, 18, 20, 20, 18, 22, 20, 18, 18, 20, 18, 18, 18, 22, 20, 22, 18, 20, 18, 18, 18, 20, 22, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 22, 18, 18, 18, 18, 22, 18, 18, 22, 18, 18, 18, 18, 20, 18, 22, 18, 18, 20, 18, 22, 20, 18, 18, 20, 20, 20, 18, 18, 26, 18, 20, 20, 20, 19, 18, 18, 20, 18, 18, 18, 18, 18, 20, 18, 20, 18, 18, 18, 18, 18, 18, 20, 18, 18, 18, 22, 20, 18, 20, 18, 18, 20, 18, 18, 20, 20, 18, 18, 18, 18, 18, 18, 20, 18, 20, 20, 20, 18, 20, 20, 18, 20, 20, 18, 20, 20, 20, 18, 18, 18, 18, 20, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 20, 18, 18, 18, 20, 18, 18, 18, 18, 18, 18, 18, 16, 20, 20, 18, 18, 20, 18, 18, 18, 20, 20, 20, 18, 20, 18, 18, 18, 18, 18, 20, 18, 20, 20, 18, 18, 18, 18, 18, 20, 18, 20, 18, 18, 22, 22, 18, 18, 20, 18, 18, 20, 18, 18, 18, 20, 20, 18, 18, 18, 20, 18, 20, 16, 16, 18, 18, 20, 22, 20, 22, 20, 18, 18, 18, 18, 18, 18, 18, 24, 22, 28, 22, 16, 18, 18, 18, 18, 18, 18, 20, 18, 22, 24, 24, 24, 22, 22, 24, 22, 22, 22, 22, 20, 18, 20, 18, 18, 24, 18, 22, 20, 18, 18, 20, 20, 18, 18, 20, 16, 18, 20, 24, 20, 18, 22, 18, 18, 18, 20, 18, 20, 20, 18, 22, 18, 18, 20, 20, 20, 18, 18, 18, 18, 16, 18, 18, 20, 18, 20, 20, 18, 20, 18, 18, 18, 20, 18, 20, 20, 22, 18, 18, 20, 20, 22, 20, 20, 20, 18, 20, 22, 20, 20, 18, 20, 18, 20, 20, 20, 20, 20, 20, 20, 18, 20, 18, 20, 18, 22, 18, 18, 18, 18, 20, 20, 20, 20, 18, 18, 20, 20, 20, 18, 18, 20, 18, 20, 18, 20, 18, 18, 18, 20, 20, 20, 18, 18, 22, 22, 22, 20, 18, 20, 18, 18, 20, 20, 20, 18, 22, 18, 20, 20, 18, 18, 20, 18, 20, 22, 20, 20, 20, 18, 20, 18, 18, 20, 18, 18, 20, 20, 20, 18, 20, 20, 20, 18, 18, 20, 20, 18, 20, 18, 20, 20, 20, 20, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 20, 18, 18, 18, 18, 22, 22, 20, 24, 20, 22, 22, 18, 18, 18, 16, 18, 20, 20, 20, 18, 18, 18, 19, 18, 21, 18, 21, 19, 18, 17, 20, 18, 18, 20, 18, 22, 19, 19, 18, 20, 20, 20, 19, 18, 20, 20, 18, 18, 19, 18, 19, 18, 18, 18, 20, 19, 21, 18, 20, 18, 19, 20, 20, 20, 20, 21, 22, 18, 18, 19, 18, 20, 19, 19, 19, 18, 20, 20, 18, 18, 20, 17, 20, 18, 19, 20, 19, 22, 19, 22, 20, 19, 18, 18, 20, 21, 20, 18, 23, 18, 21, 19, 18, 19, 18, 18, 19, 20, 20, 19, 18, 20, 17, 18, 19, 19, 20, 19, 19, 20, 21, 18, 19, 19, 20, 20, 18, 19, 18, 16, 18, 19, 18, 19, 18, 20, 19, 18, 18, 19, 18, 18, 18, 18, 19, 19, 18, 18, 21, 18, 20, 21, 18, 19, 18, 18, 18, 18, 18, 20, 19, 20, 20, 18, 18, 19, 21, 18, 20, 20, 18, 21, 20, 23, 20, 18, 18, 22, 20, 20, 20, 19, 20, 18, 21, 20, 18, 18, 18, 18, 18, 19, 18, 18, 20, 20, 20, 18, 18, 18, 18, 20, 20, 18, 17, 20], 'Cycle(R/I)': [2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 3, 4, 3, 3, 4, 4, 2, 4, 2, 2, 4, 3, 2, 2, 4, 2, 3, 2, 3, 3, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 4, 3, 2, 4, 4, 3, 3, 3, 3, 2, 3, 3, 2, 4, 4, 2, 3, 3, 3, 2, 2, 3, 2, 2, 3, 4, 4, 2, 2, 3, 4, 3, 2, 2, 2, 2, 4, 2, 3, 2, 2, 3, 3, 4, 2, 2, 4, 4, 2, 4, 2, 3, 4, 4, 3, 4, 3, 2, 2, 2, 3, 4, 4, 2, 3, 4, 4, 4, 4, 4, 2, 2, 2, 2, 3, 3, 4, 2, 3, 3, 3, 4, 2, 3, 2, 2, 2, 2, 4, 4, 4, 4, 2, 3, 2, 2, 2, 4, 3, 2, 2, 2, 2, 4, 2, 3, 2, 2, 4, 4, 4, 3, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 3, 4, 2, 4, 4, 2, 4, 4, 3, 2, 2, 3, 4, 2, 2, 4, 4, 2, 2, 2], 'Pregnant(Y/N)': [0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0], 'Weight gain(Y/N)': [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0], 'hair growth(Y/N)': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1], 'Skin darkening (Y/N)': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1], 'Pimples(Y/N)': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0], 'Fast food (Y/N)': [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6947849330397046, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5834900521296338, 1.0, 1.0, 1.0, 1.0, 0.906828441545754, 1.0, 0.3523098794586377, 1.0, 1.0, 0.304781258158029, 1.0, 1.0, 1.0, 0.3075639671097296, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7531239371613988, 0.3036957271602116, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4110370133182313, 1.0, 1.0, 1.0, 0.6807054515547668, 1.0, 0.4477831645730916, 0.447106910928672, 1.0, 1.0, 1.0, 0.7578400617225741, 0.8031397563798959, 0.4703006344460384, 1.0, 1.0, 0.8164318732193839, 1.0, 0.8492824560345705, 1.0, 1.0, 1.0, 0.6740410947981152, 0.7797589524344517, 0.0, 0.1904989538602846, 0.6513340127082706, 0.9038234489085792, 0.940523264489604, 0.3975720210875223, 0.5177513505274801, 0.162289894092672, 1.0, 0.7352161192407721, 1.0, 1.0, 0.6957843993450822, 1.0, 0.1749549270959361, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5582934536070976, 1.0, 0.1887071083413793, 1.0, 0.7003578299727713, 0.1533388577616941, 1.0, 1.0, 1.0, 0.1490715512324872, 0.0, 0.7853406511139436, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8240747473226546, 0.0, 0.4938937151834346, 0.0, 1.0, 0.7441705230565623, 1.0, 0.6919392081476108, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5132578470405449, 0.906098787718554, 1.0, 1.0, 0.6451033620305648, 1.0, 1.0, 0.7698147317584447, 1.0, 1.0, 1.0, 0.9563962282455662, 0.994550510797341, 1.0, 1.0, 1.0, 0.7477187738974139, 1.0, 1.0, 1.0, 1.0, 0.0196684162839543, 1.0, 0.3056970192871818, 0.190911031150346, 0.7315251431098432, 0.5147201257236843, 1.0, 1.0, 0.1557868592736886, 1.0, 1.0, 1.0, 1.0, 0.3586467812961639, 0.7458363509302612, 1.0, 1.0, 0.1513302050753255, 1.0, 0.2910890030898814, 0.0, 1.0, 1.0, 1.0, 0.6115137108656805, 1.0, 0.0051848627739867, 0.0, 0.8057260464879578, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.250251360515864, 1.0], 'Reg.Exercise(Y/N)': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'PCOS (Y/N)': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'Cycle length(days)': [5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 2, 5, 5, 5, 5, 5, 5, 7, 6, 9, 5, 5, 5, 5, 3, 3, 5, 3, 4, 4, 5, 5, 5, 5, 7, 5, 5, 0, 5, 5, 9, 5, 7, 5, 5, 5, 5, 3, 10, 5, 4, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 2, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 12, 4, 11, 5, 5, 5, 2, 5, 5, 5, 5, 5, 9, 5, 2, 5, 5, 5, 11, 5, 5, 5, 5, 12, 5, 5, 5, 11, 2, 5, 9, 5, 7, 8, 9, 11, 6, 2, 5, 9, 5, 5, 5, 9, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 11, 5, 5, 5, 5, 5, 2, 5, 2, 4, 5, 4, 5, 4, 4, 6, 4, 5, 6, 5, 4, 5, 5, 6, 5, 6, 4, 5, 6, 4, 6, 5, 6, 4, 4, 4, 5, 6, 4, 5, 5, 5, 6, 5, 5, 5, 6, 4, 4, 3, 5, 5, 3, 4, 4, 5, 5, 3, 6, 5, 6, 4, 6, 5, 4, 5, 6, 4, 5, 4, 5, 5, 6, 3, 5, 4, 6, 4, 4, 3, 5, 5, 6, 5, 6, 6, 4, 5, 5, 5, 4, 6, 6, 5, 3, 3, 4, 5, 5, 6, 5, 6, 6, 4, 5, 5, 5, 4, 4, 3, 4, 5, 5, 6, 5, 6, 6, 5, 5, 4, 5, 5, 4, 3, 5, 6, 3, 4, 5, 6, 6, 4, 5, 5, 4, 5, 4, 3, 5, 5, 4, 6, 6, 5, 5, 5, 3, 5, 6, 6, 4, 5, 5, 5, 4, 6, 6, 5, 5, 4, 3, 5, 5, 5, 5, 6, 5, 3, 5, 2, 5, 5, 6, 6, 5, 6, 5, 5, 5, 3, 6, 2, 5, 6, 6, 5, 2, 6, 6, 3, 6, 5, 5, 5, 3, 3, 2, 5, 2, 5, 5, 5, 6, 3, 2, 6, 5, 2, 6, 2, 6, 6, 2, 6, 3, 6, 6, 6, 5, 6, 3, 6, 5, 5, 2, 6, 3, 5, 6, 6, 3, 5, 6, 4, 6, 3, 6, 6, 5, 3, 6, 6, 7, 3, 6, 5, 5, 2, 2, 6, 5, 5, 6, 3, 6, 6, 4, 6, 5, 6, 3, 5, 6, 5, 6, 5, 6, 6, 5, 5, 5, 5, 4, 2, 5, 6, 4, 5, 5, 6, 2, 5, 5, 3, 5, 2, 6, 5, 3, 6, 5, 6, 5, 5, 6, 3, 2, 5, 6, 3, 6, 7, 5, 2, 5, 7, 7, 2, 5, 4, 5, 5, 5, 5, 6, 2, 7, 5, 4, 5, 7, 5, 7, 4, 4, 2, 5, 5, 7, 5, 5, 5, 2, 4, 5, 7, 5, 5, 5, 5, 5, 2, 5, 5, 2, 2, 5, 4, 7, 2, 5, 4, 5, 2, 5, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5, 4, 5, 4, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 7, 5, 5, 7, 4, 6, 6, 5, 5, 4, 7, 5, 5, 5, 5, 6, 2, 7, 3, 4, 2, 3, 3, 2, 2, 2, 5, 8, 5, 5, 3, 4, 4, 5, 10, 4, 2, 6, 2, 4, 5, 5, 3, 5, 5, 4, 4, 4, 5, 5, 3, 3, 4, 5, 6, 4, 4, 3, 4, 3, 5, 3, 6, 4, 3, 2, 5, 3, 5, 2, 3, 8, 3, 4, 2, 2, 4, 4, 3, 3, 5, 4, 6, 4, 4, 2, 2, 3, 5, 3, 4, 2, 5, 5, 5, 4, 3, 2, 4, 2, 5, 5, 2, 2, 3, 5, 4, 2, 2, 5, 6, 5, 3, 2, 6, 4, 3, 3, 4, 4, 5, 2, 4, 2, 5, 6, 3, 7, 9, 2, 3, 5, 4, 6, 4, 5, 3, 6, 5, 6, 6, 4, 5, 5, 6, 3, 5, 5, 3, 2, 2, 5, 3, 4, 3, 5, 3, 4, 5, 5, 4, 5, 4, 4, 6, 4, 3, 3, 3, 6, 7, 7, 10, 5, 4, 6, 5, 4, 5, 4, 4, 5, 5, 3, 4, 6, 3, 5, 2, 4, 3, 5, 6, 3, 4, 5, 3, 2, 3, 4, 10, 5, 4, 4, 4], 'No. of abortions': [0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 3, 1, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 5, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1, 3, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 4, 1, 2, 1, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Follicle No. (L)': [3, 3, 13, 2, 3, 9, 6, 7, 5, 1, 7, 4, 15, 3, 4, 1, 6, 1, 0, 16, 1, 4, 5, 6, 4, 1, 21, 3, 7, 11, 10, 5, 8, 2, 11, 1, 6, 1, 7, 6, 5, 8, 0, 6, 13, 5, 4, 5, 6, 5, 22, 7, 6, 4, 5, 6, 6, 3, 3, 5, 6, 9, 3, 4, 11, 2, 1, 14, 7, 11, 5, 5, 3, 3, 2, 0, 4, 7, 0, 1, 8, 8, 2, 2, 2, 4, 8, 11, 10, 11, 4, 7, 2, 2, 3, 6, 18, 13, 3, 4, 7, 5, 12, 1, 11, 12, 6, 11, 11, 5, 1, 5, 5, 5, 14, 5, 4, 21, 7, 2, 3, 1, 6, 10, 8, 7, 2, 1, 0, 2, 4, 3, 3, 12, 3, 4, 4, 6, 8, 5, 3, 13, 6, 0, 3, 9, 0, 3, 4, 6, 4, 12, 7, 3, 6, 7, 5, 3, 9, 5, 3, 1, 10, 3, 2, 5, 4, 11, 9, 18, 12, 13, 3, 15, 1, 12, 15, 11, 12, 3, 8, 15, 1, 3, 4, 5, 7, 2, 1, 7, 6, 14, 2, 2, 5, 8, 12, 5, 6, 12, 2, 2, 3, 14, 5, 15, 16, 3, 5, 8, 12, 12, 1, 8, 6, 9, 14, 9, 6, 3, 1, 7, 14, 4, 6, 6, 12, 1, 2, 6, 4, 1, 16, 7, 1, 0, 5, 6, 5, 10, 12, 6, 6, 4, 9, 8, 1, 10, 7, 4, 10, 0, 14, 1, 2, 5, 4, 2, 9, 10, 1, 1, 4, 5, 10, 6, 3, 7, 6, 9, 7, 2, 4, 8, 4, 12, 6, 1, 4, 3, 3, 4, 8, 3, 1, 1, 2, 10, 1, 5, 1, 1, 2, 11, 13, 9, 8, 7, 1, 1, 2, 7, 3, 10, 3, 4, 8, 2, 6, 6, 1, 12, 7, 7, 5, 8, 8, 4, 6, 1, 7, 5, 7, 14, 4, 4, 2, 4, 7, 6, 1, 3, 3, 4, 6, 2, 8, 16, 12, 1, 10, 10, 4, 10, 3, 1, 10, 6, 4, 1, 10, 10, 4, 6, 7, 5, 9, 1, 2, 2, 3, 2, 1, 1, 3, 2, 8, 5, 8, 3, 15, 4, 12, 8, 1, 9, 1, 8, 3, 6, 6, 5, 8, 2, 5, 4, 3, 16, 6, 3, 10, 1, 10, 1, 8, 10, 4, 3, 6, 3, 4, 5, 11, 4, 4, 2, 1, 2, 3, 3, 1, 3, 10, 1, 12, 8, 6, 3, 4, 3, 14, 2, 13, 4, 6, 8, 7, 3, 11, 14, 4, 5, 4, 5, 8, 4, 4, 9, 11, 7, 9, 3, 6, 12, 1, 8, 6, 14, 9, 6, 20, 5, 10, 11, 12, 6, 14, 7, 14, 4, 5, 0, 13, 2, 21, 6, 11, 13, 9, 12, 8, 5, 12, 5, 9, 6, 2, 18, 3, 5, 7, 5, 1, 7, 9, 2, 16, 4, 5, 7, 3, 6, 1, 9, 5, 10, 5, 9, 1, 8, 3, 2, 3, 3, 7, 3, 3, 6, 1, 20, 8, 9, 8, 1, 9, 10, 12, 5, 5, 4, 18, 8, 6, 6, 9, 2, 5, 10, 1, 3, 10, 2, 9, 8, 7, 7, 1, 9, 1, 7, 9, 10, 9, 15, 8, 15, 10, 4, 15, 8, 5, 12, 11, 6, 9, 10, 4, 12, 4, 11, 16, 13, 6, 12, 12, 9, 13, 9, 8, 7, 8, 12, 11, 8, 20, 11, 10, 12, 12, 3, 8, 10, 12, 7, 9, 12, 6, 6, 8, 8, 3, 11, 15, 9, 19, 8, 8, 4, 17, 9, 13, 13, 10, 11, 18, 13, 15, 10, 6, 7, 6, 13, 11, 5, 3, 6, 11, 8, 8, 9, 10, 8, 10, 13, 8, 11, 12, 7, 10, 9, 11, 9, 11, 9, 13, 5, 7, 20, 15, 9, 11, 11, 12, 4, 9, 15, 7, 6, 17, 6, 8, 16, 13, 13, 8, 9, 6, 9, 6, 8, 14, 16, 15, 10, 11, 6, 10, 10, 6, 1, 9, 9, 9, 13, 6, 5, 9, 10, 2, 10, 8, 14, 6, 12, 10, 8, 7, 14, 6, 8, 7, 10, 6, 13, 8, 11, 7, 7, 14, 11, 16, 10, 12, 11, 10, 10, 10, 7, 10, 9, 9, 16, 7, 10, 13, 8, 11, 12, 10, 9, 14, 7, 13, 4, 8, 11, 8, 10], 'Follicle No. (R)': [3, 5, 15, 2, 4, 6, 6, 6, 7, 1, 15, 2, 8, 3, 1, 3, 5, 2, 2, 8, 2, 2, 7, 8, 6, 2, 20, 2, 4, 10, 8, 10, 9, 5, 7, 1, 2, 2, 5, 12, 8, 10, 1, 8, 14, 8, 6, 7, 8, 8, 18, 10, 11, 6, 9, 7, 5, 2, 3, 7, 7, 12, 5, 7, 10, 4, 2, 12, 9, 8, 2, 6, 1, 4, 3, 2, 4, 4, 2, 2, 6, 6, 2, 6, 2, 4, 10, 9, 13, 9, 2, 5, 2, 1, 5, 10, 13, 10, 2, 2, 10, 2, 12, 0, 12, 8, 4, 10, 10, 4, 1, 4, 3, 6, 5, 3, 4, 20, 9, 4, 2, 1, 10, 13, 10, 6, 3, 0, 1, 1, 8, 7, 3, 9, 4, 7, 4, 4, 5, 7, 2, 12, 7, 5, 3, 10, 4, 3, 12, 2, 9, 14, 5, 5, 5, 7, 7, 5, 7, 7, 5, 1, 11, 2, 3, 5, 6, 12, 12, 20, 14, 12, 2, 16, 1, 13, 14, 8, 14, 5, 6, 16, 1, 4, 5, 7, 8, 3, 2, 9, 6, 16, 4, 2, 6, 10, 11, 7, 4, 12, 1, 4, 2, 16, 6, 18, 15, 4, 7, 10, 15, 11, 1, 7, 7, 7, 6, 12, 6, 2, 1, 6, 10, 3, 6, 7, 13, 3, 4, 5, 2, 1, 14, 5, 3, 5, 5, 5, 5, 5, 9, 4, 5, 7, 7, 10, 2, 15, 10, 6, 15, 1, 11, 3, 3, 7, 1, 5, 8, 15, 3, 0, 1, 5, 7, 5, 2, 10, 5, 4, 6, 3, 4, 7, 6, 15, 5, 1, 8, 2, 3, 5, 5, 5, 1, 2, 1, 7, 0, 3, 1, 3, 2, 12, 20, 10, 5, 9, 0, 0, 1, 5, 4, 12, 2, 5, 12, 4, 9, 7, 2, 6, 12, 9, 5, 12, 4, 6, 6, 2, 20, 11, 11, 19, 7, 4, 4, 3, 10, 4, 2, 3, 3, 1, 7, 2, 10, 12, 10, 1, 15, 7, 15, 5, 5, 1, 12, 4, 8, 3, 6, 7, 5, 4, 4, 7, 12, 1, 2, 3, 3, 3, 1, 3, 3, 2, 11, 7, 11, 4, 12, 9, 9, 7, 2, 10, 2, 7, 5, 7, 6, 5, 5, 3, 3, 2, 1, 14, 7, 5, 9, 2, 11, 2, 7, 9, 9, 4, 9, 3, 4, 5, 12, 11, 5, 3, 3, 3, 6, 0, 1, 4, 18, 1, 14, 12, 2, 3, 9, 3, 10, 4, 12, 5, 3, 12, 3, 11, 9, 16, 6, 7, 6, 7, 11, 3, 4, 12, 9, 13, 6, 5, 2, 11, 1, 7, 7, 11, 7, 8, 16, 18, 19, 15, 13, 7, 10, 6, 5, 1, 8, 4, 12, 1, 19, 9, 9, 12, 10, 12, 10, 14, 14, 7, 10, 15, 1, 11, 5, 8, 5, 9, 3, 12, 10, 4, 16, 4, 9, 15, 2, 5, 2, 19, 8, 11, 4, 7, 1, 7, 5, 7, 1, 3, 10, 3, 10, 6, 1, 18, 10, 5, 10, 3, 7, 8, 10, 8, 4, 4, 20, 10, 5, 9, 10, 3, 3, 9, 0, 1, 11, 0, 7, 10, 7, 9, 0, 7, 0, 6, 10, 12, 12, 19, 10, 15, 12, 9, 13, 9, 6, 11, 12, 11, 12, 12, 7, 10, 9, 11, 10, 11, 8, 11, 9, 9, 12, 14, 13, 6, 9, 9, 10, 13, 19, 12, 15, 10, 16, 2, 11, 19, 9, 11, 12, 12, 10, 9, 9, 10, 8, 11, 16, 14, 16, 12, 14, 9, 16, 19, 12, 15, 15, 11, 15, 8, 13, 14, 9, 6, 5, 12, 8, 6, 10, 5, 15, 12, 10, 6, 7, 9, 15, 10, 12, 11, 11, 7, 18, 11, 9, 11, 14, 10, 11, 7, 6, 19, 18, 11, 12, 16, 13, 2, 9, 16, 9, 5, 11, 5, 10, 14, 10, 14, 9, 8, 5, 9, 6, 8, 9, 15, 8, 10, 15, 8, 8, 8, 9, 2, 11, 10, 9, 16, 9, 5, 5, 11, 1, 9, 4, 14, 6, 15, 12, 7, 12, 6, 10, 9, 12, 13, 9, 13, 10, 10, 15, 9, 11, 9, 12, 8, 18, 14, 9, 12, 11, 12, 10, 14, 10, 17, 10, 11, 9, 9, 9, 19, 11, 8, 14, 16, 13, 4, 5, 8, 12, 14], 'Waist:Hip Ratio': [0.83, 0.84, 0.9, 0.86, 0.81, 0.86, 0.85, 0.86, 0.9, 0.95, 0.9, 0.85, 0.89, 0.85, 0.79, 0.93, 0.81, 0.82, 0.89, 0.95, 0.87, 0.81, 0.89, 0.89, 0.84, 0.82, 0.84, 0.83, 0.81, 0.83, 0.82, 0.93, 0.82, 0.81, 0.84, 0.86, 0.84, 0.81, 0.82, 0.86, 0.88, 0.86, 0.81, 0.85, 0.85, 0.83, 0.91, 0.85, 0.87, 0.89, 0.81, 0.84, 0.82, 0.87, 0.9, 0.84, 0.85, 0.83, 0.89, 0.89, 0.86, 0.87, 0.88, 0.87, 0.88, 0.85, 0.89, 0.85, 0.89, 0.88, 0.83, 0.83, 0.88, 0.89, 0.86, 0.84, 0.85, 0.88, 0.89, 0.85, 0.87, 0.9, 0.9, 0.85, 0.82, 0.88, 0.86, 0.89, 0.89, 0.88, 0.88, 0.86, 0.87, 0.84, 0.83, 0.84, 0.88, 0.82, 0.98, 0.83, 0.88, 0.83, 0.86, 0.84, 0.82, 0.86, 0.84, 0.84, 0.87, 0.88, 0.83, 0.85, 0.88, 0.87, 0.84, 0.84, 0.83, 0.82, 0.82, 0.82, 0.83, 0.79, 0.82, 0.83, 0.87, 0.8, 0.79, 0.8, 0.79, 0.82, 0.86, 0.83, 0.76, 0.86, 0.79, 0.79, 0.81, 0.85, 0.85, 0.79, 0.81, 0.79, 0.76, 0.82, 0.81, 0.82, 0.83, 0.84, 0.89, 0.82, 0.86, 0.8, 0.78, 0.88, 0.84, 0.78, 0.86, 0.81, 0.85, 0.84, 0.89, 0.85, 0.83, 0.84, 0.83, 0.83, 0.84, 0.79, 0.85, 0.8, 0.94, 0.86, 0.83, 0.81, 0.84, 0.83, 0.9, 0.88, 0.93, 0.89, 0.84, 0.89, 0.94, 0.92, 0.84, 0.83, 0.9, 0.89, 0.85, 0.92, 0.83, 0.9, 0.86, 0.94, 0.94, 0.92, 0.89, 0.9, 0.91, 0.95, 0.89, 0.95, 0.9, 0.94, 0.95, 0.9, 0.9, 0.92, 0.92, 0.92, 0.92, 0.94, 0.9, 0.94, 0.89, 0.9, 0.94, 0.92, 0.94, 0.95, 0.94, 0.88, 0.91, 0.89, 0.95, 0.94, 0.94, 0.95, 0.95, 0.95, 0.92, 0.9, 0.91, 0.88, 0.94, 0.94, 0.92, 0.91, 0.91, 0.94, 0.94, 0.92, 0.92, 0.93, 0.96, 0.92, 0.94, 0.9, 0.95, 0.94, 0.91, 0.93, 0.95, 0.94, 0.94, 0.94, 0.93, 0.91, 0.93, 0.94, 0.94, 0.94, 0.94, 0.91, 0.91, 0.93, 0.94, 0.94, 0.94, 0.94, 0.94, 0.92, 0.93, 0.94, 0.94, 0.85, 0.95, 0.94, 0.9, 0.94, 0.95, 0.91, 0.94, 0.95, 0.94, 0.91, 0.94, 0.94, 0.95, 0.95, 0.92, 0.94, 0.95, 0.93, 0.92, 0.94, 0.91, 0.94, 0.95, 0.88, 0.95, 0.91, 0.91, 0.93, 0.94, 0.94, 0.94, 0.92, 0.84, 0.82, 0.89, 0.84, 0.82, 0.84, 0.89, 0.89, 0.9, 0.83, 0.89, 0.89, 0.83, 0.88, 0.9, 0.92, 0.9, 0.89, 0.92, 0.92, 0.87, 0.92, 0.92, 0.89, 0.89, 0.86, 0.92, 0.91, 0.86, 0.91, 0.9, 0.89, 0.9, 0.88, 0.89, 0.9, 0.9, 0.92, 0.88, 0.92, 0.89, 0.86, 0.87, 0.87, 0.88, 0.92, 0.92, 0.88, 0.9, 0.89, 0.92, 0.92, 0.87, 0.9, 0.86, 0.86, 0.83, 0.88, 0.84, 0.92, 0.89, 0.92, 0.92, 0.9, 0.93, 0.86, 0.89, 0.89, 0.92, 0.9, 0.92, 0.89, 0.89, 0.95, 0.97, 0.89, 0.89, 0.9, 0.89, 0.84, 0.92, 0.89, 0.92, 0.92, 0.89, 0.92, 0.86, 0.9, 0.93, 0.89, 0.92, 0.9, 0.92, 0.92, 0.89, 0.89, 0.89, 0.89, 0.89, 0.89, 0.92, 0.92, 0.89, 0.88, 0.89, 0.89, 0.92, 0.9, 0.88, 0.93, 0.92, 0.89, 0.87, 0.9, 0.92, 0.89, 0.88, 0.89, 0.89, 0.86, 0.87, 0.89, 0.89, 0.92, 0.88, 0.88, 0.9, 0.9, 0.84, 0.9, 0.93, 0.9, 0.88, 0.89, 0.88, 0.95, 0.89, 0.95, 0.95, 0.92, 0.93, 0.95, 0.95, 0.86, 0.83, 0.84, 0.87, 0.89, 0.86, 0.96, 0.95, 0.97, 0.95, 0.95, 0.87, 0.97, 0.97, 0.94, 0.97, 0.87, 0.89, 0.95, 0.89, 0.94, 0.9, 0.88, 0.95, 0.84, 0.88, 0.98, 0.95, 0.97, 0.97, 0.85, 0.88, 0.96, 0.92, 0.88, 0.89, 0.93, 0.98, 0.98, 0.95, 0.97, 0.94, 0.97, 0.96, 0.9, 0.93, 0.94, 0.94, 0.97, 0.95, 0.91, 0.97, 0.94, 0.86, 0.97, 0.86, 0.98, 0.94, 0.93, 0.94, 0.95, 0.95, 0.95, 0.95, 0.96, 0.88, 0.94, 0.93, 0.93, 0.96, 0.96, 0.89, 0.95, 0.95, 0.92, 0.95, 0.95, 0.95, 0.93, 0.89, 0.92, 0.88, 0.93, 0.93, 0.92, 0.93, 0.94, 0.93, 0.93, 0.96, 0.8962650427566691, 0.8946015890869833, 0.939693877526523, 0.9188570714111596, 0.9198865466488536, 0.8938956986607941, 0.868367251268932, 0.8774612428880276, 0.9018253474335086, 0.87, 0.8943465429517089, 0.7921844043721684, 0.895009403127778, 0.9211671974108112, 0.8691910518904746, 0.9214538431709528, 0.8663187189500067, 0.9227951467536274, 0.8927867750615365, 0.8329538024108272, 0.9200104075399064, 0.909422934309975, 0.8843825006526423, 0.91, 0.8413635767750176, 0.9448482997135896, 0.8776807570398757, 0.8892235066480592, 0.8141775731146884, 0.9065367166261656, 0.8621876421957307, 0.8965138798789596, 0.9078849148682588, 0.8419467674132695, 0.9274608458606566, 0.8596251275406321, 0.887332615444419, 0.905613529496222, 0.94259565350233, 0.8998192388039153, 0.8566781014275284, 0.929064598233306, 0.9135585194672708, 0.8973559413679562, 0.87, 0.8761221613641637, 0.89, 0.8806186916663428, 0.9255221683542691, 0.8689421382185735, 0.9355618034327636, 0.8851488004200371, 0.8569654456061404, 0.8248431987655485, 0.8998430121810053, 0.8823270571001435, 0.8606630743642063, 0.8639294665466731, 0.8556995377492862, 0.8458841587489185, 0.9075358771982714, 0.9, 0.9095812806790882, 0.9485835880481372, 0.95, 0.895595179048689, 0.9642229906487604, 0.8609548849246312, 0.8769733197458346, 0.8828852965327426, 0.7953529061959357, 0.9121699585238734, 0.8837574054630764, 0.8746060904683405, 0.8156740871256791, 0.8617740656911073, 0.9070021217188516, 0.8516579189531026, 0.924789219967254, 0.860857999128108, 0.944751352187122, 0.9, 0.9206654356508406, 0.902608291748304, 0.8600749260048415, 0.869654193512888, 0.937668261855716, 0.847604548521599, 0.93, 0.9188451458963128, 0.9149821085013614, 0.8522671086209355, 0.9485059433502474, 0.8519098374575562, 0.8855108039504384, 0.9540371379507004, 0.9693563499422094, 0.8085863739554423, 0.9133797650942846, 0.8893519364994482, 0.9088315170031478, 0.92, 0.9202633616324468, 0.9271607902526254, 0.903053638603444, 0.9548561375358622, 0.8451575857013753, 0.9791686193916233, 0.88, 0.9307230145446208, 0.824816811455503, 0.8843058167377063, 0.8463353121541713, 0.927208526152828, 0.8360469962126065, 0.9476775683259044, 0.8037237930833531, 0.9252644223051628, 0.8809031974553201, 0.9249538181394416, 0.9294935423780272, 0.9483114286620008, 0.906193206233649, 0.9256340727368868, 0.87, 0.91, 0.8722551681015283, 0.913378481193262, 0.95, 0.8884148214593244, 0.8699193379884752, 0.874320251952551, 0.9223144598569368, 0.95, 0.9495095459717606, 0.8977049937408151, 0.9276351726562592, 0.9511650597773372, 0.907659685827181, 0.9353071847023952, 0.856305042653872, 0.9265829490050648, 0.8815063222253755, 0.927836474208765, 0.8492465374399387, 0.9402593874926664, 0.942363558753986, 0.93, 0.919116792456579, 0.8498149493675239, 0.9242123413276212, 0.9422106570363156, 0.8548988215632417, 0.8850708708405319, 0.8450702461138432, 0.89, 0.939240596561115, 0.9276249094720922, 0.8593296588106744, 0.946774492357614, 0.8815133020507533, 0.9159013600567392, 0.8632871202471905, 0.8765845993072372, 0.8822093913811321, 0.8709890428223138, 0.8404965554875566, 0.9150362339779112, 0.9091840581959976, 0.949585210978081, 0.9265104973453772, 0.9383435627892774, 0.8385129100399913, 0.9103216172786112, 0.95, 0.9254646859580264, 0.9175144905313666, 0.8363248614941685, 0.9175389649207236, 0.899517647823432, 0.8632815266747473, 0.9, 0.8503631822337894, 0.9206720202483236, 0.8725635843519493, 0.9274874319742068, 0.938446610622823], 'Avg. F size (L) (mm)': [18.0, 15.0, 18.0, 15.0, 16.0, 16.0, 15.0, 15.0, 17.0, 14.0, 17.0, 18.0, 20.0, 18.0, 19.0, 14.0, 20.0, 20.0, 0.0, 18.0, 18.0, 17.0, 16.0, 14.0, 18.0, 15.0, 11.0, 10.0, 12.0, 13.0, 14.0, 14.0, 12.0, 14.0, 14.0, 11.0, 11.0, 6.5, 8.0, 13.0, 14.0, 11.0, 0.0, 8.0, 16.0, 14.0, 10.0, 15.0, 10.0, 14.0, 12.0, 15.0, 12.0, 13.0, 10.0, 9.5, 11.0, 12.0, 16.0, 14.0, 13.0, 14.0, 12.0, 11.0, 14.5, 12.0, 10.0, 8.0, 5.0, 9.5, 11.5, 12.0, 7.5, 10.5, 9.5, 0.0, 10.5, 15.0, 0.0, 8.0, 13.0, 16.0, 15.0, 14.0, 13.0, 16.0, 15.0, 17.0, 15.0, 15.0, 15.0, 20.0, 14.0, 14.0, 20.0, 19.0, 17.0, 19.0, 20.0, 18.0, 19.0, 17.5, 17.0, 14.0, 18.0, 18.0, 19.0, 16.0, 15.0, 17.0, 11.0, 17.0, 19.0, 18.0, 15.0, 15.5, 15.0, 15.0, 18.0, 18.0, 16.0, 15.0, 16.0, 18.0, 16.0, 18.0, 18.0, 17.0, 15.0, 19.0, 16.0, 15.0, 16.0, 19.0, 18.0, 15.0, 14.0, 17.0, 18.0, 15.0, 9.0, 16.0, 18.5, 0.0, 21.0, 17.0, 0.0, 17.0, 18.0, 19.0, 15.0, 14.0, 15.0, 16.0, 12.0, 14.0, 11.0, 12.0, 13.0, 11.0, 11.0, 11.0, 14.0, 10.0, 13.0, 14.0, 12.0, 14.0, 14.0, 16.0, 13.0, 15.0, 14.0, 13.0, 10.0, 15.0, 14.0, 15.0, 14.0, 10.0, 12.0, 13.0, 11.0, 13.0, 10.0, 13.0, 13.0, 11.0, 13.0, 16.0, 11.0, 16.0, 10.0, 10.0, 13.0, 15.0, 14.0, 12.0, 10.0, 14.0, 11.0, 12.0, 12.0, 17.0, 12.0, 15.0, 12.0, 14.0, 12.0, 13.0, 15.0, 17.0, 17.0, 17.0, 16.0, 14.0, 15.0, 15.0, 17.0, 14.0, 16.0, 14.0, 16.0, 14.0, 17.0, 16.0, 14.0, 11.0, 16.0, 14.0, 17.0, 13.0, 15.0, 17.0, 14.0, 17.0, 18.0, 15.0, 17.0, 15.0, 15.0, 16.0, 15.0, 10.0, 16.0, 17.0, 14.0, 18.0, 16.0, 18.0, 15.0, 17.0, 16.0, 18.0, 15.0, 16.0, 18.5, 17.0, 18.0, 17.0, 15.0, 19.0, 17.0, 19.0, 18.0, 18.0, 19.0, 19.0, 17.0, 20.0, 19.0, 18.0, 17.0, 18.0, 17.0, 16.0, 18.0, 12.0, 15.0, 15.0, 18.0, 16.0, 15.0, 17.0, 11.0, 20.0, 16.0, 18.0, 15.0, 16.0, 14.0, 16.0, 12.0, 13.0, 14.0, 18.0, 17.0, 13.0, 16.0, 15.0, 18.0, 16.0, 16.0, 15.0, 17.0, 17.0, 11.0, 12.5, 13.0, 15.0, 15.0, 17.0, 15.0, 11.0, 12.0, 14.0, 16.0, 14.0, 15.0, 16.0, 15.0, 8.0, 15.0, 18.0, 10.0, 10.0, 10.0, 18.0, 13.0, 16.0, 12.0, 13.0, 14.0, 11.0, 15.0, 14.0, 15.0, 11.0, 10.0, 10.0, 14.0, 10.0, 15.0, 15.0, 10.0, 10.0, 15.0, 10.0, 11.0, 12.0, 15.0, 13.0, 15.0, 13.0, 15.0, 15.0, 15.0, 14.0, 10.0, 13.0, 13.0, 10.0, 14.0, 13.0, 16.0, 15.0, 13.0, 15.0, 15.0, 12.0, 18.0, 12.0, 17.0, 15.0, 13.0, 14.0, 18.0, 19.0, 18.0, 18.0, 12.0, 13.0, 16.0, 18.0, 15.0, 14.0, 11.0, 12.0, 18.0, 15.0, 19.0, 15.0, 15.0, 13.0, 16.0, 15.0, 12.0, 12.0, 19.0, 18.0, 14.0, 14.0, 19.0, 18.0, 18.0, 14.0, 17.0, 17.0, 14.0, 10.0, 13.0, 2.0, 14.0, 13.0, 14.0, 12.0, 14.0, 14.0, 10.0, 13.0, 15.0, 10.0, 15.0, 14.0, 12.0, 17.0, 19.0, 19.0, 19.0, 16.0, 13.0, 14.0, 10.0, 13.0, 14.0, 11.0, 14.0, 18.0, 16.0, 15.0, 19.0, 11.0, 9.0, 19.0, 16.0, 20.0, 18.0, 20.0, 19.0, 19.0, 18.0, 11.0, 17.0, 19.0, 19.0, 18.0, 17.0, 17.0, 19.0, 22.0, 18.0, 0.0, 19.0, 19.0, 16.0, 20.0, 21.0, 19.0, 22.0, 24.0, 17.0, 15.0, 19.0, 19.0, 18.0, 18.0, 20.0, 20.0, 18.0, 18.0, 20.0, 16.0, 19.0, 20.0, 18.0, 15.0, 19.0, 18.0, 20.0, 16.0, 19.0, 18.0, 19.0, 19.0, 18.0, 18.0, 18.0, 20.0, 7.0, 18.0, 17.0, 19.0, 21.0, 17.0, 18.0, 18.0, 16.0, 19.0, 16.0, 18.0, 18.0, 19.0, 16.0, 7.0, 18.0, 20.0, 19.0, 20.0, 19.0, 19.0, 20.0, 19.0, 17.5, 17.0, 21.0, 16.0, 6.8, 21.0, 19.0, 18.0, 21.0, 21.0, 17.0, 18.0, 20.0, 13.0, 17.5, 19.0, 18.0, 18.0, 19.0, 15.791165241444366, 15.539841091301671, 18.17244897738708, 15.05714642944202, 19.197730932977077, 12.626532198678673, 15.119532160984742, 10.375645951866208, 13.52183157081143, 18.10549425983027, 15.26079257710254, 14.0, 16.666039791481467, 14.766560517837735, 18.675654978994725, 10.610439773503368, 19.0, 11.024887142996706, 15.272132249384637, 15.0, 15.0, 12.64743114366583, 17.0, 15.012064881142347, 15.0, 18.515170028641016, 15.69243603289027, 17.461175332402956, 14.511748955504451, 14.495126873481208, 19.0, 16.34861201210405, 16.211508513174124, 11.194676741326944, 15.269577069671724, 17.4937521256772, 16.69630427283979, 13.712270589924442, 17.5557392101398, 17.98644291029365, 15.800343042825856, 16.976614955832652, 16.233111039954693, 17.900847801298355, 19.0, 11.462594621194544, 14.361410903109531, 14.061869166634272, 17.552216835426908, 17.211572356285313, 16.963483619396968, 18.67658669466914, 16.108963368184213, 15.0, 15.818838538279376, 16.118797462215845, 14.950269422684528, 10.601175557555448, 17.36713625356123, 15.201654875015448, 17.205740351723435, 15.967204893037126, 16.17487684074529, 17.85835880481372, 18.977876715605653, 14.660723142696645, 19.0, 12.61900209227943, 13.0, 14.09617655109142, 16.059476735510398, 14.204855957824956, 14.0, 18.837710105907327, 14.027070351117844, 17.529567761518457, 14.209071620737712, 15.082895947655132, 18.47892199672541, 13.0, 19.0754958019447, 14.071326626682255, 16.450092326186958, 15.913366601356728, 16.992507399515848, 18.965419351288794, 16.4417065463929, 17.35209097043198, 14.81129289165862, 16.836614057776547, 13.198568680108917, 19.153338857761693, 18.42529716751237, 16.16844311014467, 13.88777009876096, 16.85092844876751, 16.25746002311621, 16.429318697772114, 15.331011745285773, 15.32274648574582, 14.372282766561742, 14.35919934525333, 16.920991510265953, 16.851762924212398, 13.778544558622428, 20.0, 16.0, 19.98337238783246, 14.35185050535469, 17.963849272768957, 13.975574860733738, 19.0, 12.90059364625142, 18.0, 13.279060075747871, 15.383878416295222, 15.5425402305549, 13.56169853787132, 14.727334763628209, 16.998152725577665, 18.410129152439456, 17.915571433100038, 16.486742152959454, 15.093901212281446, 15.171971827552143, 13.899529553831949, 16.29020672406113, 16.682468417641697, 11.95082704449668, 15.611296877690886, 15.500806620115249, 14.139979003954084, 17.76855401430631, 16.043603771754434, 18.005449489202658, 16.7103884020634, 14.559120683593518, 17.766988044532518, 14.756843678307758, 19.671502929167676, 14.984501828023085, 13.86935476784843, 13.572292469170838, 15.0, 13.0, 15.082908942138454, 18.236355875398612, 14.268474856890156, 18.85279874276316, 13.881939398717853, 17.394691466809473, 16.68842628145262, 16.27993266075667, 16.85916773830091, 19.0, 15.328856483175947, 17.054885405742198, 18.98334540372105, 10.885871765256816, 17.0323477072842, 10.33231612791429, 14.13662133144203, 17.544554984550594, 10.366160277105108, 18.0, 12.320876574214894, 14.231379169216623, 16.38848628913432, 15.0, 20.963705960582093, 19.627894414948635, 15.805726046487958, 14.0, 16.412864691144446, 16.203074124157588, 16.77323429790132, 13.972383228126295, 15.157729791015118, 17.192370615090436, 19.3279738647048, 13.625221339797855, 14.0, 10.545397779223672, 15.644265991722548, 19.0, 12.501508163095185, 17.03883473442942], 'Avg. F size (R) (mm)': [18.0, 14.0, 20.0, 14.0, 14.0, 20.0, 16.0, 18.0, 17.0, 17.0, 20.0, 19.0, 21.0, 17.0, 21.0, 20.0, 20.0, 18.0, 17.0, 17.0, 19.0, 17.0, 17.0, 18.0, 17.0, 17.0, 12.0, 11.0, 17.0, 14.0, 14.0, 13.0, 13.0, 12.0, 19.0, 12.0, 13.0, 8.5, 7.0, 12.0, 14.0, 12.0, 12.0, 8.0, 15.0, 13.0, 12.0, 18.0, 15.0, 13.0, 13.0, 13.0, 11.0, 14.0, 11.0, 11.0, 13.0, 13.0, 17.0, 15.0, 14.0, 13.0, 13.5, 11.0, 14.0, 14.0, 12.0, 5.0, 8.5, 7.0, 4.7, 6.0, 4.5, 6.0, 6.2, 5.8, 10.5, 12.0, 9.0, 9.0, 15.0, 15.0, 17.0, 18.0, 15.0, 13.0, 13.0, 18.0, 16.0, 16.0, 7.0, 18.0, 15.0, 15.0, 19.0, 19.0, 18.0, 16.0, 18.0, 18.0, 20.0, 18.0, 9.0, 0.0, 20.0, 17.5, 16.0, 14.0, 16.0, 21.0, 10.0, 19.0, 20.0, 21.0, 14.0, 15.0, 14.0, 17.0, 20.0, 20.0, 14.0, 18.0, 15.0, 17.0, 18.0, 17.0, 18.0, 15.0, 9.0, 12.0, 18.0, 14.0, 17.0, 18.0, 17.0, 17.0, 13.0, 18.0, 15.0, 13.0, 18.0, 18.0, 16.0, 19.0, 18.0, 18.0, 18.0, 18.0, 16.0, 19.0, 18.0, 18.0, 16.0, 19.0, 14.0, 16.0, 13.0, 12.0, 16.0, 12.0, 13.0, 12.0, 16.0, 11.0, 14.0, 13.0, 12.0, 15.0, 16.0, 15.0, 15.0, 16.0, 12.0, 14.0, 11.0, 16.0, 12.0, 14.0, 16.0, 11.0, 11.0, 14.0, 12.0, 12.0, 13.0, 14.0, 12.0, 12.0, 13.0, 15.0, 12.0, 17.0, 13.0, 11.0, 12.0, 13.0, 14.0, 14.0, 14.0, 17.0, 14.0, 12.0, 14.0, 15.0, 15.0, 19.0, 14.0, 12.0, 13.0, 15.0, 18.0, 14.0, 16.0, 14.0, 14.0, 14.0, 13.0, 13.0, 16.0, 15.0, 12.0, 16.0, 15.0, 18.0, 16.0, 15.0, 17.0, 12.0, 12.0, 13.0, 10.0, 10.0, 18.0, 15.0, 16.0, 18.0, 20.0, 17.0, 19.0, 18.0, 18.0, 19.0, 18.0, 15.0, 13.0, 18.0, 16.0, 19.0, 19.0, 17.0, 17.0, 15.0, 19.0, 14.0, 18.0, 17.0, 19.0, 18.0, 19.0, 18.0, 17.0, 20.0, 13.0, 18.0, 18.0, 17.0, 18.0, 19.0, 19.0, 16.0, 18.0, 18.0, 18.0, 16.0, 17.0, 18.0, 16.0, 14.0, 18.0, 13.0, 15.0, 19.0, 17.0, 16.0, 16.0, 17.0, 14.0, 14.0, 18.0, 17.0, 15.0, 17.0, 16.0, 15.0, 16.0, 19.0, 15.0, 17.0, 12.0, 18.0, 15.0, 13.0, 14.0, 14.0, 15.0, 16.0, 11.5, 12.0, 13.0, 16.0, 11.0, 18.0, 18.0, 15.0, 10.0, 18.0, 17.0, 18.0, 18.0, 17.0, 17.0, 12.0, 18.0, 19.0, 16.0, 15.0, 15.0, 13.0, 17.0, 17.0, 18.0, 10.0, 12.0, 10.0, 11.0, 15.0, 12.0, 9.0, 10.0, 12.0, 11.0, 11.0, 12.0, 17.0, 11.0, 10.0, 17.0, 11.0, 15.0, 15.0, 12.0, 15.0, 18.0, 15.0, 18.0, 18.0, 15.0, 16.0, 15.0, 11.0, 14.0, 10.0, 13.0, 13.0, 15.0, 14.0, 15.0, 14.0, 14.0, 15.0, 20.0, 17.0, 19.0, 15.0, 14.0, 12.0, 11.0, 15.0, 18.0, 22.0, 15.0, 15.0, 12.0, 20.0, 17.0, 11.0, 12.0, 15.0, 12.0, 12.0, 15.0, 11.0, 13.0, 15.0, 15.0, 14.0, 15.0, 11.0, 17.0, 19.0, 16.0, 16.0, 17.0, 20.0, 20.0, 24.0, 20.0, 18.0, 12.0, 11.0, 15.0, 13.0, 14.0, 14.0, 14.0, 16.0, 13.0, 13.0, 15.0, 15.0, 15.0, 16.0, 15.0, 10.0, 11.0, 0.17, 17.0, 17.0, 15.0, 16.0, 14.0, 15.0, 13.0, 11.0, 15.0, 16.0, 13.0, 19.0, 19.0, 19.0, 14.0, 12.0, 11.0, 19.0, 17.0, 20.0, 19.0, 19.0, 18.0, 17.0, 14.0, 21.0, 18.0, 21.0, 18.0, 18.0, 17.0, 19.0, 19.0, 14.0, 19.0, 20.0, 18.0, 18.0, 18.0, 18.0, 16.0, 19.0, 17.0, 18.0, 20.0, 20.0, 18.0, 20.0, 19.0, 20.0, 17.0, 19.0, 17.0, 18.0, 21.0, 19.0, 19.0, 14.0, 17.0, 18.0, 19.0, 19.0, 19.0, 16.0, 16.0, 20.0, 18.0, 18.0, 18.0, 16.0, 16.0, 16.0, 17.0, 20.0, 18.0, 19.0, 19.0, 18.0, 16.0, 18.0, 21.0, 19.0, 19.0, 17.0, 19.0, 19.0, 18.0, 19.0, 18.0, 17.0, 16.0, 21.0, 20.0, 16.0, 19.0, 21.0, 16.5, 22.0, 23.0, 19.0, 12.0, 18.0, 14.0, 17.0, 12.0, 16.0, 18.0, 18.0, 19.0, 17.5, 10.0, 18.0, 9.0, 16.0, 18.0, 11.41766951711127, 16.920317817396654, 19.40612244946954, 13.228585717768077, 18.398298199732803, 9.779139732158818, 18.119532160984743, 10.751291903732414, 13.591267371675428, 20.683517220509188, 17.17386171806836, 15.6553213116505, 14.666039791481465, 13.233439482162265, 18.351309957989454, 15.36626386410202, 17.068893514230925, 15.745372467633969, 15.0, 15.056929638375912, 14.998959246009369, 13.237155718329156, 17.30478125815803, 14.506032440571175, 16.0, 16.575850143205084, 18.61512793421946, 18.73058766620148, 15.755874477752226, 12.663417915654138, 18.0, 15.0, 17.19232765788392, 12.06489224710898, 15.746084586065656, 18.2468760628386, 17.30369572716021, 15.712270589924442, 15.0, 18.98192388039153, 17.0, 18.92984486749796, 16.466222079909386, 18.933898534198903, 18.0, 16.09694596589591, 14.0, 14.469065416682865, 18.0, 17.44710691092867, 15.55618034327636, 18.83829334733457, 18.369654456061404, 16.273520185167722, 2.400426560215779, 18.118797462215845, 17.966846281789685, 11.202351115110892, 18.0, 16.403309750030896, 17.15071754396543, 14.934409786074252, 17.78325122716353, 14.0, 18.95575343121131, 13.32144628539329, 18.288850467561986, 14.428503138419146, 14.65133401270827, 16.09617655109142, 18.0, 16.807283936737434, 15.51775135052748, 16.837710105907327, 14.054140702235683, 18.26478388075923, 13.836286482950854, 17.082895947655132, 16.0, 14.7714499782027, 21.60036058323251, 11.142653253364514, 16.3835487611029, 17.174195776187137, 9.033716702178682, 18.94812902693319, 16.76682618557161, 18.11736365681066, 13.81129289165862, 18.44225729481564, 16.898926510081687, 20.69332228447661, 17.856324291878092, 16.78647561863343, 13.33668970371712, 18.40371379507005, 18.06436500577905, 16.07329674443028, 14.324046981143086, 11.515880271381272, 15.255434466876514, 14.299332787711108, 10.158016979468096, 18.432158050525068, 15.946361396556066, 17.08631747848264, 17.448424142986248, 18.99445746261082, 16.527775758032035, 18.0, 13.493893715183434, 19.0, 14.53412486166856, 18.744170523056564, 16.558120151495743, 13.616121583704778, 17.085080461109797, 13.01762815367752, 17.0, 16.749538181394417, 15.640516609757825, 16.915571433100038, 17.513257847040546, 17.812197575437107, 18.737577462041717, 13.949764776915972, 17.87062017218339, 16.668924059663098, 12.407497304784291, 15.301852682415554, 15.0, 16.855991601581636, 19.0, 19.1308113152633, 16.005449489202658, 16.0, 17.27956034179676, 14.766988044532518, 15.261406130512931, 15.85921554107186, 15.653751523352568, 13.10552993367098, 15.144584938341676, 14.059005248851864, 15.773961231981616, 16.0, 18.80908896884965, 13.268474856890156, 15.426399371381578, 17.2546262658119, 17.210617066381054, 20.90949198508418, 15.279932660756671, 19.788751607451367, 16.62675615284608, 13.315425932703798, 20.130825749630688, 19.0, 11.885871765256816, 14.9676522927158, 7.907981230451954, 15.72675733711594, 18.96237697837083, 12.301030196282785, 19.110469569056605, 13.48131486132234, 17.487586112811083, 17.61151371086568, 16.83681163919952, 22.94815137226013, 19.0, 18.417178139463875, 16.070940916999927, 16.603216172786112, 18.101537062078798, 18.206320042654617, 15.94476645625259, 16.736594686522675, 15.438474123018088, 19.0, 20.34369466505053, 12.465124850183232, 10.58171600260261, 16.838933502069363, 17.860404618311676, 8.66465208535526, 17.922330531141153], 'Endometrium (mm)': [8.5, 3.7, 10.0, 7.5, 7.0, 8.0, 6.8, 7.1, 4.2, 2.5, 6.0, 7.8, 8.0, 5.6, 5.5, 3.9, 5.6, 4.0, 5.6, 11.0, 5.7, 7.6, 7.6, 8.5, 7.3, 8.8, 6.8, 10.0, 6.2, 5.0, 7.0, 6.0, 7.5, 8.5, 8.0, 7.0, 10.0, 10.0, 15.0, 0.0, 7.3, 6.5, 6.5, 7.12, 7.0, 9.4, 9.0, 16.0, 9.0, 10.4, 11.0, 10.0, 6.0, 6.8, 6.3, 8.9, 8.6, 9.3, 14.0, 11.0, 7.2, 7.8, 9.6, 8.6, 12.5, 9.4, 9.7, 5.5, 6.2, 8.9, 6.5, 6.0, 5.4, 9.8, 8.7, 8.5, 12.8, 18.0, 8.6, 10.0, 8.5, 8.3, 0.0, 6.0, 10.0, 12.0, 10.0, 4.6, 10.0, 8.0, 6.0, 5.7, 8.3, 9.0, 6.8, 6.0, 5.9, 5.0, 5.0, 7.5, 6.8, 6.4, 11.3, 7.0, 7.0, 9.0, 4.4, 7.0, 9.0, 9.3, 8.5, 10.0, 7.0, 9.0, 8.7, 8.3, 9.8, 11.0, 8.0, 11.7, 8.6, 6.2, 13.4, 12.5, 8.5, 12.0, 8.5, 9.0, 14.0, 9.7, 8.0, 11.5, 9.7, 12.0, 9.0, 11.0, 11.0, 10.7, 9.0, 8.5, 9.0, 11.0, 8.0, 7.0, 9.3, 7.5, 10.7, 8.0, 10.0, 7.1, 10.0, 8.0, 8.5, 8.0, 14.0, 7.5, 11.0, 10.0, 9.0, 9.5, 6.0, 5.0, 9.4, 8.5, 4.6, 6.5, 4.0, 10.0, 9.0, 10.7, 9.6, 8.5, 5.5, 9.5, 5.0, 9.0, 8.0, 8.0, 11.0, 5.0, 4.5, 9.3, 5.5, 9.0, 9.0, 6.5, 5.9, 9.7, 6.3, 13.0, 6.0, 9.0, 6.0, 7.0, 7.0, 5.5, 5.6, 9.0, 6.0, 10.5, 6.0, 9.8, 9.9, 10.6, 8.5, 8.0, 5.5, 7.5, 6.5, 5.5, 6.1, 15.0, 9.4, 6.0, 5.0, 10.0, 9.7, 10.0, 10.2, 14.0, 10.0, 10.0, 8.0, 8.7, 7.7, 12.0, 13.0, 6.0, 10.8, 8.5, 12.0, 8.8, 11.5, 9.0, 8.5, 4.8, 7.0, 9.0, 9.0, 8.0, 8.0, 14.0, 9.0, 9.2, 9.6, 9.0, 8.0, 10.3, 12.0, 11.0, 8.3, 13.0, 9.3, 6.0, 8.0, 8.2, 8.5, 9.0, 10.0, 8.0, 8.4, 10.0, 6.5, 8.7, 9.0, 8.0, 5.6, 10.0, 7.0, 13.0, 8.0, 8.7, 8.3, 7.0, 10.3, 8.7, 8.8, 9.5, 7.2, 9.0, 8.9, 7.0, 9.8, 9.8, 11.0, 7.2, 7.8, 9.0, 7.7, 8.0, 8.5, 9.0, 10.5, 5.5, 9.6, 8.0, 8.5, 9.6, 7.7, 11.0, 7.0, 9.0, 9.5, 9.0, 12.0, 5.6, 5.5, 8.0, 6.0, 7.0, 7.3, 12.0, 11.0, 7.8, 11.0, 8.5, 10.0, 7.7, 8.4, 6.4, 12.0, 10.5, 8.0, 12.0, 9.0, 11.0, 13.0, 9.0, 8.0, 6.0, 9.0, 6.0, 10.5, 12.0, 11.0, 9.0, 10.0, 9.0, 9.3, 8.2, 10.0, 8.7, 11.0, 8.0, 9.2, 13.0, 10.0, 11.0, 10.8, 14.0, 9.0, 9.0, 8.0, 5.6, 10.6, 7.0, 11.0, 6.4, 12.0, 6.8, 13.5, 7.0, 9.2, 7.0, 9.0, 8.5, 9.8, 11.0, 10.0, 8.0, 12.0, 9.0, 8.0, 11.0, 7.5, 10.3, 9.0, 5.5, 11.2, 9.0, 10.0, 6.5, 7.0, 8.0, 7.5, 7.0, 8.3, 7.5, 9.0, 11.2, 10.0, 9.0, 10.3, 7.5, 11.0, 8.0, 7.0, 8.0, 5.8, 9.6, 7.0, 8.0, 11.0, 7.0, 9.5, 6.8, 9.0, 11.0, 9.0, 4.0, 8.0, 11.0, 10.3, 13.0, 9.5, 6.5, 8.0, 9.0, 6.7, 7.8, 10.0, 7.2, 8.2, 11.0, 8.5, 11.2, 9.0, 8.9, 11.5, 10.2, 7.6, 7.0, 7.0, 10.0, 11.0, 9.0, 10.0, 8.0, 10.0, 10.3, 8.0, 3.0, 7.0, 8.1, 8.55, 6.0, 5.9, 6.0, 8.0, 8.2, 7.0, 9.65, 8.5, 7.85, 8.2, 9.0, 7.0, 8.0, 8.0, 10.5, 7.35, 8.9, 7.9, 7.2, 7.6, 8.0, 8.0, 7.0, 8.15, 8.9, 7.0, 7.5, 8.95, 5.0, 9.0, 8.5, 6.4, 9.2, 6.0, 9.0, 8.0, 4.5, 8.6, 8.0, 7.25, 8.5, 10.5, 6.75, 6.8, 10.0, 6.0, 7.2, 10.35, 6.0, 7.0, 6.4, 5.4, 6.6, 6.0, 8.8, 14.2, 9.0, 9.3, 6.8, 10.0, 7.0, 7.0, 7.5, 9.1, 7.8, 8.4, 6.0, 9.3, 8.5, 9.0, 7.0, 9.2, 9.8, 5.9, 6.5, 7.8, 8.0, 10.0, 7.6, 6.5, 7.8, 6.8, 6.2, 9.7, 7.3, 4.8, 8.5, 7.0, 10.3, 8.2, 9.6, 6.7, 8.2, 7.3, 11.5, 6.9, 10.514257406938835, 8.81952327390502, 8.175663265759324, 5.700012503047066, 8.281361440213757, 9.664263426343677, 10.0, 8.360885120334483, 9.974802945578515, 8.883956314186703, 7.771732714758545, 9.563119125566333, 9.541839057342598, 9.474761165134908, 6.583821037809493, 9.297670363760538, 6.104523298038622, 6.681365688309151, 9.615087696800105, 9.510312722754866, 8.200780565492973, 7.439128709837929, 7.304781258158029, 8.164655853142941, 7.801134129063163, 8.54551008592305, 8.330923239468325, 9.6803516322634, 7.767623433256677, 5.331708957827069, 11.168695965622334, 8.848612012104047, 7.674961067126359, 6.8648922471089815, 10.746084586065656, 8.376561968580699, 7.698500172468487, 9.427362353954663, 7.592347719813599, 7.9954809700978835, 10.879519740043802, 8.051447097168165, 8.177925973363537, 8.099152198701645, 8.003521374408004, 7.175343251888227, 9.23369308373144, 9.530934583317135, 9.71788188605498, 8.497603780164196, 7.3480336037326675, 10.621279989499072, 11.369654456061404, 10.44303214196192, 10.077896611365407, 9.675751586115096, 9.941980993131953, 7.797061106111383, 8.04107968304846, 9.004137187538623, 8.984928245603458, 10.147540366977784, 7.847906403395441, 8.133129561490241, 9.53318492659152, 7.537493800112348, 6.577700935123964, 9.07610397533092, 8.511867617791578, 9.90382344890858, 10.69666864889698, 8.397572021087523, 8.75887567526374, 8.883771010590733, 9.310774707401798, 8.367608059620386, 7.045358103688568, 8.91269682355519, 12.087353198035249, 8.085799912810801, 6.534990985419188, 10.00534949700117, 9.845009232618697, 9.960922072720468, 11.28763720920115, 7.069161297422413, 10.791467268035488, 8.582154559767462, 8.433878674975862, 10.278871352592182, 7.33899807607624, 7.566323113140866, 7.345394695177914, 10.179713427950144, 10.242878138265343, 8.745357756162436, 7.61287300115581, 10.227749432450675, 6.6585411085002, 8.867982404331437, 9.748913106624697, 9.290467048602224, 11.973663836755318, 8.807531906102644, 8.305363860344393, 6.971227507172453, 9.648639150316306, 9.196120223827574, 9.64814949464531, 10.251196518238094, 9.024425139266262, 7.178822709221329, 8.193768673917708, 8.255829476943438, 8.720939924252129, 9.261133128962372, 9.170160922219598, 7.47355776948372, 10.209066094548715, 10.499076362788832, 7.799751847256939, 10.93245714648003, 8.180493048193254, 6.466214727897639, 8.434394365510428, 8.350078407694676, 7.603324284548039, 6.03175315823583, 6.135832434928097, 7.500759151285978, 10.804194424599288, 8.853976904349492, 11.074216057225236, 11.808143404280491, 8.800544948920267, 11.120221944036228, 9.940879316406482, 7.302915542107726, 6.205474942646206, 12.671502929167673, 9.03694957346128, 7.34170509949353, 7.632545358185856, 9.039336832567908, 8.773961231981616, 9.694302980712818, 8.668188609026211, 6.80542457067047, 9.672080188585529, 9.322909098076778, 7.368493653104845, 8.129675321530542, 6.930016834810832, 7.281664523398176, 6.0445935880768005, 10.73691481345924, 6.571729356259233, 6.838740041930138, 8.93623247073515, 7.9031421398680815, 9.111862287105456, 9.654648532576813, 8.330296855098304, 6.557744018473674, 9.199422612150943, 9.125934256933885, 9.84706875382494, 8.406481534991066, 8.52030428708065, 6.506740321606183, 7.502315531958908, 11.611452092975917, 9.47803500869992, 10.206432345572225, 9.13246384756999, 8.34014855314802, 9.472962849380956, 11.0, 11.876948246036171, 7.26237909176384, 8.78039543119196, 8.465124850183233, 12.73099537558002, 9.026880809932944, 11.469537549584366, 6.926432754940425, 7.937864424912923]}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "ds698B_yfqad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "cols_to_scale = df.drop('PCOS (Y/N)',axis=1).columns.to_list()\n",
        "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
      ],
      "metadata": {
        "id": "SEDifviSj0ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop('PCOS (Y/N)',axis=1)\n",
        "y = df['PCOS (Y/N)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.2,random_state=123)"
      ],
      "metadata": {
        "id": "czTFw812f_Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Patient Info"
      ],
      "metadata": {
        "id": "_iXuHZeEhMp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_record = [0.28, 70, 35, 23.1, 18, 2, 0, 0, 0, 0, 1, 0, 1, 5, 0, 3, 2, 0.94, 17.0, 15, 12]\n",
        "patient_record_scaled = scaler.transform(np.array(patient_record).reshape(1, -1))\n",
        "\n",
        "print(f'Original Record of Patient: {patient_record}')\n",
        "print(f'Scaled Record of Patient: {patient_record_scaled}')\n",
        "print('=='*40)\n",
        "print('=='*40)\n",
        "print('Avoid the following message.')\n",
        "print('=='*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IP3yEQV4iPW1",
        "outputId": "1f6a3732-ab7a-46fa-d877-985fb384e713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Record of Patient: [0.28, 70, 35, 23.1, 18, 2, 0, 0, 0, 0, 1, 0, 1, 5, 0, 3, 2, 0.94, 17.0, 15, 12]\n",
            "Scaled Record of Patient: [[-0.99715165 -0.83443956  0.76942793 -0.37747187 -0.75617189 -0.70129685\n",
            "  -0.71440426 -0.82305489 -0.6260746  -0.70565033  1.01662164 -1.23042708\n",
            "   1.97127016  0.17052613 -0.39252017 -0.93684712 -1.23978751  1.07163073\n",
            "   0.54219647 -0.19570039  1.71593565]]\n",
            "================================================================================\n",
            "================================================================================\n",
            "Avoid the following message.\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNBE"
      ],
      "metadata": {
        "id": "JNPndHLPo4d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "OuSb9lsgo6Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert into numpy arrays\n",
        "X_train, X_test, y_train, y_test = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)"
      ],
      "metadata": {
        "id": "Cy_RfK3tpzqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "PzFaSoBLsZEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare base models\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
        "lgb_model = lgb.LGBMClassifier(verbose=-1)\n",
        "\n",
        "# Train XGBoost and LightGBM\n",
        "xgb_model.fit(X_train, y_train)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Get base model predictions\n",
        "xgb_train_pred = xgb_model.predict_proba(X_train)[:, 1]  # Probability of class 1\n",
        "lgb_train_pred = lgb_model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "xgb_test_pred = xgb_model.predict_proba(patient_record_scaled)[:, 1]\n",
        "lgb_test_pred = lgb_model.predict_proba(patient_record_scaled)[:, 1]\n",
        "\n",
        "# Stack predictions as new training data for the meta-learner\n",
        "stacked_train = np.column_stack((xgb_train_pred, lgb_train_pred))\n",
        "stacked_test = np.column_stack((xgb_test_pred, lgb_test_pred))\n",
        "\n",
        "# Simplified Keras Meta-Learner Model\n",
        "meta_model = Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(2,)),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "meta_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping and learning rate scheduler\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_scheduler = LearningRateScheduler(lambda epoch, lr: lr * 0.9 if epoch > 10 else lr)\n",
        "\n",
        "# Train meta-learner with validation split\n",
        "meta_model.fit(stacked_train, y_train, epochs=100, batch_size=16, verbose=1, validation_split=0.2,\n",
        "               callbacks=[early_stopping, lr_scheduler])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DMIaC3n8p7E1",
        "outputId": "91fd6633-5840-4735-f361-e3ee9028eb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:27:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.0961 - loss: 0.7670 - val_accuracy: 0.5043 - val_loss: 0.6796 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6020 - loss: 0.6565 - val_accuracy: 1.0000 - val_loss: 0.5904 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.5795 - val_accuracy: 1.0000 - val_loss: 0.5419 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.5359 - val_accuracy: 1.0000 - val_loss: 0.4906 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.4843 - val_accuracy: 1.0000 - val_loss: 0.4379 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.4157 - val_accuracy: 1.0000 - val_loss: 0.3882 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3952 - val_accuracy: 1.0000 - val_loss: 0.3434 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3253 - val_accuracy: 1.0000 - val_loss: 0.3046 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2912 - val_accuracy: 1.0000 - val_loss: 0.2711 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2661 - val_accuracy: 1.0000 - val_loss: 0.2406 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2533 - val_accuracy: 1.0000 - val_loss: 0.2124 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.2028 - val_accuracy: 1.0000 - val_loss: 0.1892 - learning_rate: 9.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1806 - val_accuracy: 1.0000 - val_loss: 0.1699 - learning_rate: 8.1000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1605 - val_accuracy: 1.0000 - val_loss: 0.1536 - learning_rate: 7.2900e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1511 - val_accuracy: 1.0000 - val_loss: 0.1395 - learning_rate: 6.5610e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1502 - val_accuracy: 1.0000 - val_loss: 0.1279 - learning_rate: 5.9049e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1245 - val_accuracy: 1.0000 - val_loss: 0.1182 - learning_rate: 5.3144e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1150 - val_accuracy: 1.0000 - val_loss: 0.1102 - learning_rate: 4.7830e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1131 - val_accuracy: 1.0000 - val_loss: 0.1030 - learning_rate: 4.3047e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1032 - val_accuracy: 1.0000 - val_loss: 0.0971 - learning_rate: 3.8742e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0977 - val_accuracy: 1.0000 - val_loss: 0.0920 - learning_rate: 3.4868e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0909 - val_accuracy: 1.0000 - val_loss: 0.0878 - learning_rate: 3.1381e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0898 - val_accuracy: 1.0000 - val_loss: 0.0839 - learning_rate: 2.8243e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0792 - val_accuracy: 1.0000 - val_loss: 0.0806 - learning_rate: 2.5419e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0841 - val_accuracy: 1.0000 - val_loss: 0.0777 - learning_rate: 2.2877e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0812 - val_accuracy: 1.0000 - val_loss: 0.0754 - learning_rate: 2.0589e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0731 - val_accuracy: 1.0000 - val_loss: 0.0733 - learning_rate: 1.8530e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0745 - val_accuracy: 1.0000 - val_loss: 0.0713 - learning_rate: 1.6677e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0734 - val_accuracy: 1.0000 - val_loss: 0.0696 - learning_rate: 1.5009e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0666 - val_accuracy: 1.0000 - val_loss: 0.0682 - learning_rate: 1.3509e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0753 - val_accuracy: 1.0000 - val_loss: 0.0669 - learning_rate: 1.2158e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0657 - val_accuracy: 1.0000 - val_loss: 0.0658 - learning_rate: 1.0942e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0670 - val_accuracy: 1.0000 - val_loss: 0.0647 - learning_rate: 9.8477e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0630 - val_accuracy: 1.0000 - val_loss: 0.0638 - learning_rate: 8.8629e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0644 - val_accuracy: 1.0000 - val_loss: 0.0630 - learning_rate: 7.9766e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0614 - val_accuracy: 1.0000 - val_loss: 0.0623 - learning_rate: 7.1790e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0616 - learning_rate: 6.4611e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0591 - val_accuracy: 1.0000 - val_loss: 0.0610 - learning_rate: 5.8150e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0654 - val_accuracy: 1.0000 - val_loss: 0.0605 - learning_rate: 5.2335e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0609 - val_accuracy: 1.0000 - val_loss: 0.0601 - learning_rate: 4.7101e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0598 - val_accuracy: 1.0000 - val_loss: 0.0596 - learning_rate: 4.2391e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 0.0593 - learning_rate: 3.8152e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0576 - val_accuracy: 1.0000 - val_loss: 0.0589 - learning_rate: 3.4337e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0641 - val_accuracy: 1.0000 - val_loss: 0.0586 - learning_rate: 3.0903e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0599 - val_accuracy: 1.0000 - val_loss: 0.0583 - learning_rate: 2.7813e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0604 - val_accuracy: 1.0000 - val_loss: 0.0581 - learning_rate: 2.5032e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0590 - val_accuracy: 1.0000 - val_loss: 0.0579 - learning_rate: 2.2528e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0594 - val_accuracy: 1.0000 - val_loss: 0.0577 - learning_rate: 2.0276e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0603 - val_accuracy: 1.0000 - val_loss: 0.0575 - learning_rate: 1.8248e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0559 - val_accuracy: 1.0000 - val_loss: 0.0573 - learning_rate: 1.6423e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0599 - val_accuracy: 1.0000 - val_loss: 0.0572 - learning_rate: 1.4781e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0558 - val_accuracy: 1.0000 - val_loss: 0.0570 - learning_rate: 1.3303e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0594 - val_accuracy: 1.0000 - val_loss: 0.0569 - learning_rate: 1.1973e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0559 - val_accuracy: 1.0000 - val_loss: 0.0568 - learning_rate: 1.0775e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0584 - val_accuracy: 1.0000 - val_loss: 0.0567 - learning_rate: 9.6977e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0584 - val_accuracy: 1.0000 - val_loss: 0.0566 - learning_rate: 8.7280e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0550 - val_accuracy: 1.0000 - val_loss: 0.0565 - learning_rate: 7.8552e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0555 - val_accuracy: 1.0000 - val_loss: 0.0565 - learning_rate: 7.0697e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0574 - val_accuracy: 1.0000 - val_loss: 0.0564 - learning_rate: 6.3627e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 1.0000 - val_loss: 0.0563 - learning_rate: 5.7264e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0546 - val_accuracy: 1.0000 - val_loss: 0.0563 - learning_rate: 5.1538e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 1.0000 - val_loss: 0.0562 - learning_rate: 4.6384e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0582 - val_accuracy: 1.0000 - val_loss: 0.0562 - learning_rate: 4.1746e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0573 - val_accuracy: 1.0000 - val_loss: 0.0561 - learning_rate: 3.7571e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0538 - val_accuracy: 1.0000 - val_loss: 0.0561 - learning_rate: 3.3814e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0562 - val_accuracy: 1.0000 - val_loss: 0.0561 - learning_rate: 3.0433e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0511 - val_accuracy: 1.0000 - val_loss: 0.0560 - learning_rate: 2.7389e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0557 - val_accuracy: 1.0000 - val_loss: 0.0560 - learning_rate: 2.4650e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0540 - val_accuracy: 1.0000 - val_loss: 0.0560 - learning_rate: 2.2185e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0573 - val_accuracy: 1.0000 - val_loss: 0.0560 - learning_rate: 1.9967e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0535 - val_accuracy: 1.0000 - val_loss: 0.0560 - learning_rate: 1.7970e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0575 - val_accuracy: 1.0000 - val_loss: 0.0559 - learning_rate: 1.6173e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 1.0000 - val_loss: 0.0559 - learning_rate: 1.4556e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 1.0000 - val_loss: 0.0559 - learning_rate: 1.3100e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0602 - val_accuracy: 1.0000 - val_loss: 0.0559 - learning_rate: 1.1790e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0575 - val_accuracy: 1.0000 - val_loss: 0.0559 - learning_rate: 1.0611e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0547 - val_accuracy: 1.0000 - val_loss: 0.0559 - learning_rate: 9.5501e-07\n",
            "Epoch 78/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0556 - val_accuracy: 1.0000 - val_loss: 0.0559 - learning_rate: 8.5950e-07\n",
            "Epoch 79/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0590 - val_accuracy: 1.0000 - val_loss: 0.0559 - learning_rate: 7.7355e-07\n",
            "Epoch 80/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0583 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 6.9620e-07\n",
            "Epoch 81/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0572 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 6.2658e-07\n",
            "Epoch 82/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0561 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 5.6392e-07\n",
            "Epoch 83/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0554 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 5.0753e-07\n",
            "Epoch 84/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 4.5678e-07\n",
            "Epoch 85/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0574 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 4.1110e-07\n",
            "Epoch 86/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0581 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 3.6999e-07\n",
            "Epoch 87/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0538 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 3.3299e-07\n",
            "Epoch 88/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 2.9969e-07\n",
            "Epoch 89/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 2.6972e-07\n",
            "Epoch 90/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0562 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 2.4275e-07\n",
            "Epoch 91/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0564 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 2.1847e-07\n",
            "Epoch 92/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0546 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 1.9663e-07\n",
            "Epoch 93/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 1.7696e-07\n",
            "Epoch 94/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0563 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 1.5927e-07\n",
            "Epoch 95/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0583 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 1.4334e-07\n",
            "Epoch 96/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0584 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 1.2901e-07\n",
            "Epoch 97/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0521 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 1.1611e-07\n",
            "Epoch 98/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0603 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 1.0450e-07\n",
            "Epoch 99/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0556 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 9.4046e-08\n",
            "Epoch 100/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0571 - val_accuracy: 1.0000 - val_loss: 0.0558 - learning_rate: 8.4642e-08\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79fc42566ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get prediction on the patient"
      ],
      "metadata": {
        "id": "Lz821rlxsbAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make final predictions\n",
        "cnbe_pred = (meta_model.predict(stacked_test) > 0.5).astype(int)\n",
        "\n",
        "if cnbe_pred == [[1]] :\n",
        "    print('PCOS Diagnosed')\n",
        "else:\n",
        "    print('PCOS Not Diagnosed')\n",
        "print('=='*40)\n",
        "print('Unfortunately, this model does not provide additional insight on interpretation, probability, or uncertainty.')\n",
        "print('You might use this model for majority voting purposes, since it has the power of combined predictions from two gradient boosting models.')\n",
        "print('=='*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cyxjbgIqOGu",
        "outputId": "3607a896-8561-472b-d39f-a0c8ee95b1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "PCOS Not Diagnosed\n",
            "================================================================================\n",
            "Unfortunately, this model does not provide additional insight on interpretation, probability, or uncertainty.\n",
            "You might use this model for majority voting purposes, since it has the power of combined predictions from two gradient boosting models.\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}